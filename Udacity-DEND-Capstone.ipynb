{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# US Immigration Data Model\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "\n",
    "The goal of the Project is to extract, clean and transform the given raw data into a readable format and to create a Data Model preferably Star Schema which could be used further by Data Analysts, Business Analysts, Data Scientists or some of interest for analytical use cases.\n",
    "\n",
    "The purpose of the data model is to make the lives of Data Scientist, Data analysts and others who are involved in doing analytics and finding a pattern to understand the trend and other required information. An use case would be to find out how many immigrants are coming to US for the study purpose or just for pleasure and to which city in the US is attracting them the most. Based on this the tourism department for example, could make more revenue by taking necessary actions. The star schema of the star data model would make the quering of the database easier and quick.\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "import configparser\n",
    "import re\n",
    "import calendar\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import IntegerType, StringType\n",
    "from pyspark.sql.functions import udf, col, count, when, isnan, create_map, lit\n",
    "from pyspark.sql.functions import year, month, dayofmonth, hour, weekofyear, date_format\n",
    "import pyspark.sql.functions as F\n",
    "from itertools import chain\n",
    "import datetime\n",
    "from pyspark.sql import Window\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "In this project I have decided to use the Udacity provided datasets to build a Data Model with Star Schema which is easy to understand and have fast analytical query performance. I have used the power of Spark (the Python API PySpark) to build ETL pipeline and I have used Python pandas library to explore the data.\n",
    " \n",
    " \n",
    "\n",
    "#### Describe and Gather Data \n",
    "\n",
    "The datasets that I have used to build the Data Model are as below :\n",
    " 1. I94 Immigration Data - The data comes from the US National Tourism and Trade Office and it contains the information about the immigrants of differnt age who arrive in the US for various purpose holding differnt type of visas.\n",
    " 2. World Temperature Data - The data comes from Kaggle and it contains the data about the temperatures recorded and its trends in different countries in the world.\n",
    " 3. U.S. City Demographic Data - The data comes from OpenSoft and it contains the demographic data of different US states and its population.\n",
    " 4. Airport Code Table - The data is taken from the website https://datahub.io/core/airport-codes#data and it contains the data about the airports and its types in different states of the US."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('dl.cfg')\n",
    "\n",
    "os.environ['AWS_ACCESS_KEY_ID']=config['AWS']['AWS_ACCESS_KEY_ID']\n",
    "os.environ['AWS_SECRET_ACCESS_KEY']=config['AWS']['AWS_SECRET_ACCESS_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat',\n",
       " '../../data/18-83510-I94-Data-2016/i94_sep16_sub.sas7bdat',\n",
       " '../../data/18-83510-I94-Data-2016/i94_nov16_sub.sas7bdat',\n",
       " '../../data/18-83510-I94-Data-2016/i94_mar16_sub.sas7bdat',\n",
       " '../../data/18-83510-I94-Data-2016/i94_jun16_sub.sas7bdat',\n",
       " '../../data/18-83510-I94-Data-2016/i94_aug16_sub.sas7bdat',\n",
       " '../../data/18-83510-I94-Data-2016/i94_may16_sub.sas7bdat',\n",
       " '../../data/18-83510-I94-Data-2016/i94_jan16_sub.sas7bdat',\n",
       " '../../data/18-83510-I94-Data-2016/i94_oct16_sub.sas7bdat',\n",
       " '../../data/18-83510-I94-Data-2016/i94_jul16_sub.sas7bdat',\n",
       " '../../data/18-83510-I94-Data-2016/i94_feb16_sub.sas7bdat',\n",
       " '../../data/18-83510-I94-Data-2016/i94_dec16_sub.sas7bdat']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of files and the name of the data files\n",
    "filenames = [os.path.join('../../data/18-83510-I94-Data-2016', file) for file in os.listdir('../../data/18-83510-I94-Data-2016')]\n",
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5111743172009784 minutes\n"
     ]
    }
   ],
   "source": [
    "# Read in the data here\n",
    "start = time.time()\n",
    "fname = filenames[0]\n",
    "df = pd.read_sas(fname, 'sas7bdat', encoding=\"ISO-8859-1\")\n",
    "end = time.time()\n",
    "print(str((end-start)/60)+ ' minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>XXX</td>\n",
       "      <td>20573.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>10282016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.897628e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20551.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>D/S</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.736796e+09</td>\n",
       "      <td>00296</td>\n",
       "      <td>F1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>WAS</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MI</td>\n",
       "      <td>20691.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OS</td>\n",
       "      <td>6.666432e+08</td>\n",
       "      <td>93</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AA</td>\n",
       "      <td>9.246846e+10</td>\n",
       "      <td>00199</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AA</td>\n",
       "      <td>9.246846e+10</td>\n",
       "      <td>00199</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode i94addr  \\\n",
       "0    6.0  2016.0     4.0   692.0   692.0     XXX  20573.0      NaN     NaN   \n",
       "1    7.0  2016.0     4.0   254.0   276.0     ATL  20551.0      1.0      AL   \n",
       "2   15.0  2016.0     4.0   101.0   101.0     WAS  20545.0      1.0      MI   \n",
       "3   16.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      MA   \n",
       "4   17.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      MA   \n",
       "\n",
       "   depdate   ...     entdepu  matflag  biryear   dtaddto gender insnum  \\\n",
       "0      NaN   ...           U      NaN   1979.0  10282016    NaN    NaN   \n",
       "1      NaN   ...           Y      NaN   1991.0       D/S      M    NaN   \n",
       "2  20691.0   ...         NaN        M   1961.0  09302016      M    NaN   \n",
       "3  20567.0   ...         NaN        M   1988.0  09302016    NaN    NaN   \n",
       "4  20567.0   ...         NaN        M   2012.0  09302016    NaN    NaN   \n",
       "\n",
       "  airline        admnum  fltno visatype  \n",
       "0     NaN  1.897628e+09    NaN       B2  \n",
       "1     NaN  3.736796e+09  00296       F1  \n",
       "2      OS  6.666432e+08     93       B2  \n",
       "3      AA  9.246846e+10  00199       B2  \n",
       "4      AA  9.246846e+10  00199       B2  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Create a Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def create_spark_sess():\n",
    "    spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .config(\"spark.jars.packages\",\"saurfang:spark-sas7bdat:2.0.0-s_2.11\")\\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:2.7.0\")\\\n",
    "    .config(\"spark.sql.broadcastTimeout\", \"36000\")\\\n",
    "    .enableHiveSupport().getOrCreate()\n",
    "    return spark\n",
    "    \n",
    "spark = create_spark_sess()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### US Immigration Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Read all the data files and write them as *parquet* files partition by *month* of the year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Month: April | Count: 3096313\n",
      "['cicid', 'i94yr', 'i94mon', 'i94cit', 'i94res', 'i94port', 'arrdate', 'i94mode', 'i94addr', 'depdate', 'i94bir', 'i94visa', 'count', 'dtadfile', 'visapost', 'occup', 'entdepa', 'entdepd', 'entdepu', 'matflag', 'biryear', 'dtaddto', 'gender', 'insnum', 'airline', 'admnum', 'fltno', 'visatype']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Month: September | Count: 3733786\n",
      "['cicid', 'i94yr', 'i94mon', 'i94cit', 'i94res', 'i94port', 'arrdate', 'i94mode', 'i94addr', 'depdate', 'i94bir', 'i94visa', 'count', 'dtadfile', 'visapost', 'occup', 'entdepa', 'entdepd', 'entdepu', 'matflag', 'biryear', 'dtaddto', 'gender', 'insnum', 'airline', 'admnum', 'fltno', 'visatype']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Month: November | Count: 2914926\n",
      "['cicid', 'i94yr', 'i94mon', 'i94cit', 'i94res', 'i94port', 'arrdate', 'i94mode', 'i94addr', 'depdate', 'i94bir', 'i94visa', 'count', 'dtadfile', 'visapost', 'occup', 'entdepa', 'entdepd', 'entdepu', 'matflag', 'biryear', 'dtaddto', 'gender', 'insnum', 'airline', 'admnum', 'fltno', 'visatype']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Month: March | Count: 3157072\n",
      "['cicid', 'i94yr', 'i94mon', 'i94cit', 'i94res', 'i94port', 'arrdate', 'i94mode', 'i94addr', 'depdate', 'i94bir', 'i94visa', 'count', 'dtadfile', 'visapost', 'occup', 'entdepa', 'entdepd', 'entdepu', 'matflag', 'biryear', 'dtaddto', 'gender', 'insnum', 'airline', 'admnum', 'fltno', 'visatype']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Month: June | Count: 3574989\n",
      "['cicid', 'i94yr', 'i94mon', 'i94cit', 'i94res', 'i94port', 'arrdate', 'i94mode', 'i94addr', 'depdate', 'i94bir', 'i94visa', 'count', 'validres', 'delete_days', 'delete_mexl', 'delete_dup', 'delete_visa', 'delete_recdup', 'dtadfile', 'visapost', 'occup', 'entdepa', 'entdepd', 'entdepu', 'matflag', 'biryear', 'dtaddto', 'gender', 'insnum', 'airline', 'admnum', 'fltno', 'visatype']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Month: August | Count: 4103570\n",
      "['cicid', 'i94yr', 'i94mon', 'i94cit', 'i94res', 'i94port', 'arrdate', 'i94mode', 'i94addr', 'depdate', 'i94bir', 'i94visa', 'count', 'dtadfile', 'visapost', 'occup', 'entdepa', 'entdepd', 'entdepu', 'matflag', 'biryear', 'dtaddto', 'gender', 'insnum', 'airline', 'admnum', 'fltno', 'visatype']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Month: May | Count: 3444249\n",
      "['cicid', 'i94yr', 'i94mon', 'i94cit', 'i94res', 'i94port', 'arrdate', 'i94mode', 'i94addr', 'depdate', 'i94bir', 'i94visa', 'count', 'dtadfile', 'visapost', 'occup', 'entdepa', 'entdepd', 'entdepu', 'matflag', 'biryear', 'dtaddto', 'gender', 'insnum', 'airline', 'admnum', 'fltno', 'visatype']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Month: January | Count: 2847924\n",
      "['cicid', 'i94yr', 'i94mon', 'i94cit', 'i94res', 'i94port', 'arrdate', 'i94mode', 'i94addr', 'depdate', 'i94bir', 'i94visa', 'count', 'dtadfile', 'visapost', 'occup', 'entdepa', 'entdepd', 'entdepu', 'matflag', 'biryear', 'dtaddto', 'gender', 'insnum', 'airline', 'admnum', 'fltno', 'visatype']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Month: October | Count: 3649136\n",
      "['cicid', 'i94yr', 'i94mon', 'i94cit', 'i94res', 'i94port', 'arrdate', 'i94mode', 'i94addr', 'depdate', 'i94bir', 'i94visa', 'count', 'dtadfile', 'visapost', 'occup', 'entdepa', 'entdepd', 'entdepu', 'matflag', 'biryear', 'dtaddto', 'gender', 'insnum', 'airline', 'admnum', 'fltno', 'visatype']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Month: July | Count: 4265031\n",
      "['cicid', 'i94yr', 'i94mon', 'i94cit', 'i94res', 'i94port', 'arrdate', 'i94mode', 'i94addr', 'depdate', 'i94bir', 'i94visa', 'count', 'dtadfile', 'visapost', 'occup', 'entdepa', 'entdepd', 'entdepu', 'matflag', 'biryear', 'dtaddto', 'gender', 'insnum', 'airline', 'admnum', 'fltno', 'visatype']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Month: February | Count: 2570543\n",
      "['cicid', 'i94yr', 'i94mon', 'i94cit', 'i94res', 'i94port', 'arrdate', 'i94mode', 'i94addr', 'depdate', 'i94bir', 'i94visa', 'count', 'dtadfile', 'visapost', 'occup', 'entdepa', 'entdepd', 'entdepu', 'matflag', 'biryear', 'dtaddto', 'gender', 'insnum', 'airline', 'admnum', 'fltno', 'visatype']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Month: December | Count: 3432990\n",
      "['cicid', 'i94yr', 'i94mon', 'i94cit', 'i94res', 'i94port', 'arrdate', 'i94mode', 'i94addr', 'depdate', 'i94bir', 'i94visa', 'count', 'dtadfile', 'visapost', 'occup', 'entdepa', 'entdepd', 'entdepu', 'matflag', 'biryear', 'dtaddto', 'gender', 'insnum', 'airline', 'admnum', 'fltno', 'visatype']\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"../../data/18-83510-I94-Data-2016/\"\n",
    "files = os.listdir(data_dir)\n",
    "for i in range(len(files)):\n",
    "    print('-'*100)\n",
    "    df_spark =spark.read.format('com.github.saurfang.sas.spark').load(data_dir + files[i])\n",
    "    print('Month: ' + calendar.month_name[int(df_spark.select('i94mon').take(1)[0][0])]+ ' | ' + 'Count: ' + str(df_spark.count()))\n",
    "    df_spark.write.partitionBy('i94mon').parquet(\"data/sas_data/\", 'append')\n",
    "    print(df_spark.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### The above process took really long and I did it on purpose to check if all the data files have the same columns but it turned out that in the month of july we have some extra columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read all the Parquet files\n",
    "dfImmig = spark.read.parquet(\"data/sas_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>i94bir</th>\n",
       "      <th>...</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "      <th>i94mon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5680949.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20659.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>1986.0</td>\n",
       "      <td>D/S</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>IG</td>\n",
       "      <td>2.947450e+09</td>\n",
       "      <td>3940</td>\n",
       "      <td>F1</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5680950.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>DET</td>\n",
       "      <td>20659.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>IL</td>\n",
       "      <td>20679.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>01232017</td>\n",
       "      <td>M</td>\n",
       "      <td>78652</td>\n",
       "      <td>DL</td>\n",
       "      <td>2.947451e+09</td>\n",
       "      <td>188</td>\n",
       "      <td>B2</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5680953.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>SEA</td>\n",
       "      <td>20659.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WA</td>\n",
       "      <td>20670.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>01232017</td>\n",
       "      <td>F</td>\n",
       "      <td>130660</td>\n",
       "      <td>OZ</td>\n",
       "      <td>2.947455e+09</td>\n",
       "      <td>272</td>\n",
       "      <td>B2</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5680954.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>ORL</td>\n",
       "      <td>20659.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>20673.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>10212016</td>\n",
       "      <td>F</td>\n",
       "      <td>294090</td>\n",
       "      <td>MT</td>\n",
       "      <td>2.947456e+09</td>\n",
       "      <td>176</td>\n",
       "      <td>WT</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5680956.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>MIA</td>\n",
       "      <td>20659.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>20728.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>01232017</td>\n",
       "      <td>M</td>\n",
       "      <td>21180</td>\n",
       "      <td>QR</td>\n",
       "      <td>2.947457e+09</td>\n",
       "      <td>777</td>\n",
       "      <td>B2</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5680958.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>ORL</td>\n",
       "      <td>20659.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>20663.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>01232017</td>\n",
       "      <td>F</td>\n",
       "      <td>154782</td>\n",
       "      <td>JJ</td>\n",
       "      <td>2.947459e+09</td>\n",
       "      <td>8086</td>\n",
       "      <td>B2</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cicid   i94yr  i94cit  i94res i94port  arrdate  i94mode i94addr  \\\n",
       "0  5680949.0  2016.0   117.0   117.0     NYC  20659.0      1.0      NY   \n",
       "1  5680950.0  2016.0   245.0   245.0     DET  20659.0      1.0      IL   \n",
       "2  5680953.0  2016.0   245.0   245.0     SEA  20659.0      1.0      WA   \n",
       "3  5680954.0  2016.0   135.0   135.0     ORL  20659.0      1.0      FL   \n",
       "4  5680956.0  2016.0   213.0   213.0     MIA  20659.0      1.0      FL   \n",
       "5  5680958.0  2016.0   689.0   689.0     ORL  20659.0      1.0      FL   \n",
       "\n",
       "   depdate  i94bir   ...    matflag  biryear   dtaddto gender  insnum airline  \\\n",
       "0      NaN    30.0   ...       None   1986.0       D/S      F    None      IG   \n",
       "1  20679.0    46.0   ...          M   1970.0  01232017      M   78652      DL   \n",
       "2  20670.0    36.0   ...          M   1980.0  01232017      F  130660      OZ   \n",
       "3  20673.0    17.0   ...          M   1999.0  10212016      F  294090      MT   \n",
       "4  20728.0    23.0   ...          M   1993.0  01232017      M   21180      QR   \n",
       "5  20663.0    56.0   ...          M   1960.0  01232017      F  154782      JJ   \n",
       "\n",
       "         admnum fltno visatype  i94mon  \n",
       "0  2.947450e+09  3940       F1     7.0  \n",
       "1  2.947451e+09   188       B2     7.0  \n",
       "2  2.947455e+09   272       B2     7.0  \n",
       "3  2.947456e+09   176       WT     7.0  \n",
       "4  2.947457e+09   777       B2     7.0  \n",
       "5  2.947459e+09  8086       B2     7.0  \n",
       "\n",
       "[6 rows x 28 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfImmig.limit(6).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cicid', 'i94yr', 'i94cit', 'i94res', 'i94port', 'arrdate', 'i94mode', 'i94addr', 'depdate', 'i94bir', 'i94visa', 'count', 'dtadfile', 'visapost', 'occup', 'entdepa', 'entdepd', 'entdepu', 'matflag', 'biryear', 'dtaddto', 'gender', 'insnum', 'airline', 'admnum', 'fltno', 'visatype', 'i94mon']\n"
     ]
    }
   ],
   "source": [
    "# Check for the column names in the Dataframe\n",
    "print(dfImmig.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- i94yr: double (nullable = true)\n",
      " |-- i94cit: double (nullable = true)\n",
      " |-- i94res: double (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: double (nullable = true)\n",
      " |-- i94mode: double (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: double (nullable = true)\n",
      " |-- i94bir: double (nullable = true)\n",
      " |-- i94visa: double (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- occup: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- entdepu: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: double (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- insnum: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: double (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      " |-- i94mon: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the Schema\n",
    "dfImmig.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43886842"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of rows\n",
    "dfImmig.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40790529"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for duplicate rows\n",
    "dfImmig.dropDuplicates().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>i94bir</th>\n",
       "      <th>...</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "      <th>i94mon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28575</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>74188</td>\n",
       "      <td>2180518</td>\n",
       "      <td>3450469</td>\n",
       "      <td>10319</td>\n",
       "      <td>...</td>\n",
       "      <td>3358010</td>\n",
       "      <td>10319</td>\n",
       "      <td>102028</td>\n",
       "      <td>4494252</td>\n",
       "      <td>38660700</td>\n",
       "      <td>1391693</td>\n",
       "      <td>0</td>\n",
       "      <td>353471</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cicid  i94yr  i94cit  i94res  i94port  arrdate  i94mode  i94addr  depdate  \\\n",
       "0      0      0   28575       0        0        0    74188  2180518  3450469   \n",
       "\n",
       "   i94bir   ...    matflag  biryear  dtaddto   gender    insnum  airline  \\\n",
       "0   10319   ...    3358010    10319   102028  4494252  38660700  1391693   \n",
       "\n",
       "   admnum   fltno  visatype  i94mon  \n",
       "0       0  353471         0       0  \n",
       "\n",
       "[1 rows x 28 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for null values in the columns of the dataframe -> very long process as the dataframe contains 40 million rows\n",
    "dfImmig.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in dfImmig.columns]).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Let's look at the Data dictionary provided along with the US Immigration Data and also gather some data from the data dictionary if required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I94YR : 4 digit year\n",
      "I94MON : Numeric month\n",
      "I94CIT & I94RES : This format shows all the valid and invalid codes for processing\n",
      "I94PORT : This format shows all the valid and invalid codes for processing\n",
      "I94MODE : There are missing values as well as not reported (9)\n",
      "I94BIR : Age of Respondent in Years\n",
      "COUNT : Used for summary statistics\n",
      "DTADFILE : Character Date Field - Date added to I-94 Files - CIC does not use\n",
      "VISAPOST : Department of State where where Visa was issued - CIC does not use\n",
      "OCCUP : Occupation that will be performed in U.S. - CIC does not use\n",
      "ENTDEPA : Arrival Flag - admitted or paroled into the U.S. - CIC does not use\n",
      "ENTDEPD : Departure Flag - Departed, lost I-94 or is deceased - CIC does not use\n",
      "ENTDEPU : Update Flag - Either apprehended, overstayed, adjusted to perm residence - CIC does not use\n",
      "MATFLAG : Match flag - Match of arrival and departure records\n",
      "BIRYEAR : 4 digit year of birth\n",
      "DTADDTO : Character Date Field - Date to which admitted to U.S. (allowed to stay until) - CIC does not use\n",
      "GENDER : Non-immigrant sex\n",
      "INSNUM : INS number\n",
      "AIRLINE : Airline used to arrive in U.S.\n",
      "ADMNUM : Admission Number\n",
      "FLTNO : Flight number of Airline used to arrive in U.S.\n",
      "VISATYPE : Class of admission legally admitting the non-immigrant to temporarily stay in U.S.\n"
     ]
    }
   ],
   "source": [
    "with open('I94_SAS_Labels_Descriptions.SAS') as f:\n",
    "    labels = f.readlines()\n",
    "    \n",
    "lines = [label for label in labels if '/*' in label and '*/\\n' in label]\n",
    "PATTERN = '^/\\*\\s+(?P<code>.+?)\\s+-\\s+(?P<description>.+)\\s+\\*/$'\n",
    "match = [re.search(PATTERN, l) for l in lines]\n",
    "\n",
    "for lab in match:\n",
    "    print(lab.group(\"code\") +\" : \"+ lab.group(\"description\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Get the valid ports\n",
    "PORT_PATTERN = re.compile(r\"^\\s*'(?P<code>...?)'\\s*=\\s*'(?P<name>.+)'.*$\")\n",
    "valid_ports = {}\n",
    "\n",
    "for lab in labels[302:961]:\n",
    "    matches = PORT_PATTERN.match(lab) \n",
    "    valid_ports.update({matches.group('code'): matches.group('name').strip().split(\",\")[0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Get the valid countries\n",
    "COUNTRY_PATT = re.compile(r\"^\\s*(\\d+)\\s*=\\s*'(.*?)'\")#\\s*([\"\"'])(?:(?=(\\\\?))\\2.)*?\\1.*$''')\n",
    "valid_country = {}\n",
    "\n",
    "for lab in labels[9:298]:\n",
    "    country = COUNTRY_PATT.search(lab) \n",
    "    valid_country.update({int(country.group(1)): country.group(2)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Get the valid address\n",
    "ADDRESS_PATT = re.compile(r\"^\\s*'(.*?)'\\s*=\\s*'(.*?)'\")#\\s*([\"\"'])(?:(?=(\\\\?))\\2.)*?\\1.*$''')\n",
    "valid_address = {}\n",
    "for lab in labels[981:1036]:\n",
    "    country = ADDRESS_PATT.search(lab) \n",
    "    valid_address.update({country.group(1): country.group(2)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "STATE_PATTERN = re.compile(r\"^\\s*'(?P<code>...?)'\\s*=\\s*'(?P<name>.+)'.*$\")\n",
    "valid_states = {}\n",
    "\n",
    "for lab in labels[302:961]:\n",
    "    matches = STATE_PATTERN.match(lab) \n",
    "    if (len(matches.group('name').strip().split(\",\"))) < 2:\n",
    "        continue\n",
    "    else:\n",
    "        valid_states.update({matches.group('code'): matches.group('name').strip().split(\",\")[1].strip()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# UDF to convert date from SAS format to datetime\n",
    "epoch = datetime.datetime(1960, 1, 1)\n",
    "sas_to_dt = udf(lambda s: (epoch + datetime.timedelta(days=int(s))).isoformat() if s is not None else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "mapping_expr = create_map([lit(x) for x in chain(*valid_country.items())])\n",
    "                          \n",
    "mapping_expr1 = create_map([lit(x) for x in chain(*valid_ports.items())])\n",
    "\n",
    "mapping_expr2 = create_map([lit(x) for x in chain(*valid_address.items())])\n",
    "\n",
    "mapping_expr3 = create_map([lit(x) for x in chain(*valid_states.items())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### I wanted to enrich the US Immigration Dataframe by adding few more columns with the data extracted from the provided data dictionary and also convert the dates from SAS format to datetime format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "dfImmig = dfImmig.withColumn('arrival_date', sas_to_dt('arrdate'))\\\n",
    "                .withColumn('departure_date', sas_to_dt('depdate'))\\\n",
    "                .withColumn(\"origin_country\", mapping_expr.getItem(col(\"i94res\")))\\\n",
    "                .withColumn(\"port\", mapping_expr1.getItem(col(\"i94port\")))\\\n",
    "                .withColumn(\"address\", mapping_expr2.getItem(col(\"i94addr\")))\\\n",
    "                .withColumn('duration_of_stay', F.datediff('departure_date', 'arrival_date'))\\\n",
    "                .withColumn('us_state', mapping_expr3.getItem(col(\"i94port\")))\\\n",
    "                .withColumn('us_state', mapping_expr2.getItem(col(\"us_state\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "dfImmig = dfImmig.withColumn('visa_purpose', F.when(col('i94visa')==1.0, 'business')\\\n",
    "            .when(col('i94visa') ==2.0, 'pleasure')\\\n",
    "            .when(col('i94visa') ==3.0, 'student').otherwise(None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "dfImmig = dfImmig.withColumn('arrival_mode', F.when(col('i94mode')==1.0, 'air')\\\n",
    "            .when(col('i94mode') ==2.0, 'sea')\\\n",
    "            .when(col('i94mode') ==3.0, 'land')\\\n",
    "            .when(col('i94mode') ==9.0, 'not reported')\\\n",
    "            .otherwise(None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "dfImmig = dfImmig.withColumn('port_type', F.when(col('i94mode')==1.0, 'airport')\\\n",
    "            .when(col('i94mode') ==2.0, 'seaport')\\\n",
    "            .when(col('i94mode') ==3.0, 'landport')\\\n",
    "            .when(col('i94mode') ==9.0, 'not reported')\\\n",
    "            .otherwise(None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>i94bir</th>\n",
       "      <th>...</th>\n",
       "      <th>arrival_date</th>\n",
       "      <th>departure_date</th>\n",
       "      <th>origin_country</th>\n",
       "      <th>port</th>\n",
       "      <th>address</th>\n",
       "      <th>duration_of_stay</th>\n",
       "      <th>us_state</th>\n",
       "      <th>visa_purpose</th>\n",
       "      <th>arrival_mode</th>\n",
       "      <th>port_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5680949.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20659.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2016-07-24T00:00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>ITALY</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>student</td>\n",
       "      <td>air</td>\n",
       "      <td>airport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5680950.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>DET</td>\n",
       "      <td>20659.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>IL</td>\n",
       "      <td>20679.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2016-07-24T00:00:00</td>\n",
       "      <td>2016-08-13T00:00:00</td>\n",
       "      <td>CHINA, PRC</td>\n",
       "      <td>DETROIT</td>\n",
       "      <td>ILLINOIS</td>\n",
       "      <td>20.0</td>\n",
       "      <td>MICHIGAN</td>\n",
       "      <td>pleasure</td>\n",
       "      <td>air</td>\n",
       "      <td>airport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5680953.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>SEA</td>\n",
       "      <td>20659.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WA</td>\n",
       "      <td>20670.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2016-07-24T00:00:00</td>\n",
       "      <td>2016-08-04T00:00:00</td>\n",
       "      <td>CHINA, PRC</td>\n",
       "      <td>SEATTLE</td>\n",
       "      <td>WASHINGTON</td>\n",
       "      <td>11.0</td>\n",
       "      <td>WASHINGTON</td>\n",
       "      <td>pleasure</td>\n",
       "      <td>air</td>\n",
       "      <td>airport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5680954.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>ORL</td>\n",
       "      <td>20659.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>20673.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2016-07-24T00:00:00</td>\n",
       "      <td>2016-08-07T00:00:00</td>\n",
       "      <td>UNITED KINGDOM</td>\n",
       "      <td>ORLANDO</td>\n",
       "      <td>FLORIDA</td>\n",
       "      <td>14.0</td>\n",
       "      <td>FLORIDA</td>\n",
       "      <td>pleasure</td>\n",
       "      <td>air</td>\n",
       "      <td>airport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5680956.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>MIA</td>\n",
       "      <td>20659.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>20728.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2016-07-24T00:00:00</td>\n",
       "      <td>2016-10-01T00:00:00</td>\n",
       "      <td>INDIA</td>\n",
       "      <td>MIAMI</td>\n",
       "      <td>FLORIDA</td>\n",
       "      <td>69.0</td>\n",
       "      <td>FLORIDA</td>\n",
       "      <td>pleasure</td>\n",
       "      <td>air</td>\n",
       "      <td>airport</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cicid   i94yr  i94cit  i94res i94port  arrdate  i94mode i94addr  \\\n",
       "0  5680949.0  2016.0   117.0   117.0     NYC  20659.0      1.0      NY   \n",
       "1  5680950.0  2016.0   245.0   245.0     DET  20659.0      1.0      IL   \n",
       "2  5680953.0  2016.0   245.0   245.0     SEA  20659.0      1.0      WA   \n",
       "3  5680954.0  2016.0   135.0   135.0     ORL  20659.0      1.0      FL   \n",
       "4  5680956.0  2016.0   213.0   213.0     MIA  20659.0      1.0      FL   \n",
       "\n",
       "   depdate  i94bir    ...             arrival_date       departure_date  \\\n",
       "0      NaN    30.0    ...      2016-07-24T00:00:00                 None   \n",
       "1  20679.0    46.0    ...      2016-07-24T00:00:00  2016-08-13T00:00:00   \n",
       "2  20670.0    36.0    ...      2016-07-24T00:00:00  2016-08-04T00:00:00   \n",
       "3  20673.0    17.0    ...      2016-07-24T00:00:00  2016-08-07T00:00:00   \n",
       "4  20728.0    23.0    ...      2016-07-24T00:00:00  2016-10-01T00:00:00   \n",
       "\n",
       "   origin_country      port     address duration_of_stay    us_state  \\\n",
       "0           ITALY  NEW YORK    NEW YORK              NaN    NEW YORK   \n",
       "1      CHINA, PRC   DETROIT    ILLINOIS             20.0    MICHIGAN   \n",
       "2      CHINA, PRC   SEATTLE  WASHINGTON             11.0  WASHINGTON   \n",
       "3  UNITED KINGDOM   ORLANDO     FLORIDA             14.0     FLORIDA   \n",
       "4           INDIA     MIAMI     FLORIDA             69.0     FLORIDA   \n",
       "\n",
       "  visa_purpose arrival_mode  port_type  \n",
       "0      student          air    airport  \n",
       "1     pleasure          air    airport  \n",
       "2     pleasure          air    airport  \n",
       "3     pleasure          air    airport  \n",
       "4     pleasure          air    airport  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's look at the US Immigration Dataframe now\n",
    "dfImmig.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+\n",
      "|arrival_mode|   count|\n",
      "+------------+--------+\n",
      "|         sea|  413533|\n",
      "|        null|   74192|\n",
      "|        land| 1161661|\n",
      "|not reported|   76863|\n",
      "|         air|42160593|\n",
      "+------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's inspect the most common mode of arrival by the immigrants\n",
    "dfImmig.groupBy('arrival_mode').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### It show that most of them arrived by airway followed by landway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+\n",
      "|visa_purpose|   count|\n",
      "+------------+--------+\n",
      "|    pleasure|36172847|\n",
      "|     student| 1616637|\n",
      "|    business| 6097358|\n",
      "+------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's inspect for what purpose immigrants visit the US\n",
    "dfImmig.groupBy('visa_purpose').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### It shows that most people visited the US for the purpose of *pleasure*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "####  US Demography Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601</td>\n",
       "      <td>41862</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562</td>\n",
       "      <td>30908</td>\n",
       "      <td>2.6</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129</td>\n",
       "      <td>49500</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147</td>\n",
       "      <td>32935</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.5</td>\n",
       "      <td>38040</td>\n",
       "      <td>46799</td>\n",
       "      <td>84839</td>\n",
       "      <td>4819</td>\n",
       "      <td>8229</td>\n",
       "      <td>2.58</td>\n",
       "      <td>AL</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rancho Cucamonga</td>\n",
       "      <td>California</td>\n",
       "      <td>34.5</td>\n",
       "      <td>88127</td>\n",
       "      <td>87105</td>\n",
       "      <td>175232</td>\n",
       "      <td>5821</td>\n",
       "      <td>33878</td>\n",
       "      <td>3.18</td>\n",
       "      <td>CA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>24437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>34.6</td>\n",
       "      <td>138040</td>\n",
       "      <td>143873</td>\n",
       "      <td>281913</td>\n",
       "      <td>5829</td>\n",
       "      <td>86253</td>\n",
       "      <td>2.73</td>\n",
       "      <td>NJ</td>\n",
       "      <td>White</td>\n",
       "      <td>76402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               City          State Median Age Male Population  \\\n",
       "0     Silver Spring       Maryland       33.8           40601   \n",
       "1            Quincy  Massachusetts       41.0           44129   \n",
       "2            Hoover        Alabama       38.5           38040   \n",
       "3  Rancho Cucamonga     California       34.5           88127   \n",
       "4            Newark     New Jersey       34.6          138040   \n",
       "\n",
       "  Female Population Total Population Number of Veterans Foreign-born  \\\n",
       "0             41862            82463               1562        30908   \n",
       "1             49500            93629               4147        32935   \n",
       "2             46799            84839               4819         8229   \n",
       "3             87105           175232               5821        33878   \n",
       "4            143873           281913               5829        86253   \n",
       "\n",
       "  Average Household Size State Code                       Race  Count  \n",
       "0                    2.6         MD         Hispanic or Latino  25924  \n",
       "1                   2.39         MA                      White  58723  \n",
       "2                   2.58         AL                      Asian   4759  \n",
       "3                   3.18         CA  Black or African-American  24437  \n",
       "4                   2.73         NJ                      White  76402  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the dataset and visualize\n",
    "df_city_demograph = spark.read.option(\"sep\", \";\").csv(\"/home/workspace/us-cities-demographics.csv\", header=True)\n",
    "df_city_demograph.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2891\n",
      "2891\n"
     ]
    }
   ],
   "source": [
    "# Count the no. of rows\n",
    "print(df_city_demograph.count())\n",
    "\n",
    "# Check for duplicates\n",
    "print(df_city_demograph.dropDuplicates().count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   City  State  Median Age  Male Population  Female Population  \\\n",
       "0     0      0           0                3                  3   \n",
       "\n",
       "   Total Population  Number of Veterans  Foreign-born  Average Household Size  \\\n",
       "0                 0                  13            13                      16   \n",
       "\n",
       "   State Code  Race  Count  \n",
       "0           0     0      0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for null values in each column of the US Demography Dataframe\n",
    "df_city_demograph.select([count(when(isnan(cc) | col(cc).isNull(), cc)).alias(cc) for cc in df_city_demograph.columns]).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Villages</td>\n",
       "      <td>Florida</td>\n",
       "      <td>70.5</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>72590</td>\n",
       "      <td>15231</td>\n",
       "      <td>4034</td>\n",
       "      <td>None</td>\n",
       "      <td>FL</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>1066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Villages</td>\n",
       "      <td>Florida</td>\n",
       "      <td>70.5</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>72590</td>\n",
       "      <td>15231</td>\n",
       "      <td>4034</td>\n",
       "      <td>None</td>\n",
       "      <td>FL</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Villages</td>\n",
       "      <td>Florida</td>\n",
       "      <td>70.5</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>72590</td>\n",
       "      <td>15231</td>\n",
       "      <td>4034</td>\n",
       "      <td>None</td>\n",
       "      <td>FL</td>\n",
       "      <td>White</td>\n",
       "      <td>72211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           City    State Median Age Male Population Female Population  \\\n",
       "0  The Villages  Florida       70.5            None              None   \n",
       "1  The Villages  Florida       70.5            None              None   \n",
       "2  The Villages  Florida       70.5            None              None   \n",
       "\n",
       "  Total Population Number of Veterans Foreign-born Average Household Size  \\\n",
       "0            72590              15231         4034                   None   \n",
       "1            72590              15231         4034                   None   \n",
       "2            72590              15231         4034                   None   \n",
       "\n",
       "  State Code                       Race  Count  \n",
       "0         FL         Hispanic or Latino   1066  \n",
       "1         FL  Black or African-American    331  \n",
       "2         FL                      White  72211  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the rows of the Dataframe where the Male Population is null\n",
    "df_city_demograph.filter(col('Male Population').isNull()).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Villages</td>\n",
       "      <td>Florida</td>\n",
       "      <td>70.5</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>72590</td>\n",
       "      <td>15231</td>\n",
       "      <td>4034</td>\n",
       "      <td>None</td>\n",
       "      <td>FL</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>1066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Villages</td>\n",
       "      <td>Florida</td>\n",
       "      <td>70.5</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>72590</td>\n",
       "      <td>15231</td>\n",
       "      <td>4034</td>\n",
       "      <td>None</td>\n",
       "      <td>FL</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Villages</td>\n",
       "      <td>Florida</td>\n",
       "      <td>70.5</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>72590</td>\n",
       "      <td>15231</td>\n",
       "      <td>4034</td>\n",
       "      <td>None</td>\n",
       "      <td>FL</td>\n",
       "      <td>White</td>\n",
       "      <td>72211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           City    State Median Age Male Population Female Population  \\\n",
       "0  The Villages  Florida       70.5            None              None   \n",
       "1  The Villages  Florida       70.5            None              None   \n",
       "2  The Villages  Florida       70.5            None              None   \n",
       "\n",
       "  Total Population Number of Veterans Foreign-born Average Household Size  \\\n",
       "0            72590              15231         4034                   None   \n",
       "1            72590              15231         4034                   None   \n",
       "2            72590              15231         4034                   None   \n",
       "\n",
       "  State Code                       Race  Count  \n",
       "0         FL         Hispanic or Latino   1066  \n",
       "1         FL  Black or African-American    331  \n",
       "2         FL                      White  72211  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the rows of the Dataframe where the Female Population is null\n",
    "df_city_demograph.filter(col('Female Population').isNull()).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### It looks like the rows which has null values are the same rows in both the cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Airport Codes Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00A</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Total Rf Heliport</td>\n",
       "      <td>11</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-PA</td>\n",
       "      <td>Bensalem</td>\n",
       "      <td>00A</td>\n",
       "      <td>None</td>\n",
       "      <td>00A</td>\n",
       "      <td>-74.93360137939453, 40.07080078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00AA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Aero B Ranch Airport</td>\n",
       "      <td>3435</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-KS</td>\n",
       "      <td>Leoti</td>\n",
       "      <td>00AA</td>\n",
       "      <td>None</td>\n",
       "      <td>00AA</td>\n",
       "      <td>-101.473911, 38.704022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00AK</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Lowell Field</td>\n",
       "      <td>450</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Anchor Point</td>\n",
       "      <td>00AK</td>\n",
       "      <td>None</td>\n",
       "      <td>00AK</td>\n",
       "      <td>-151.695999146, 59.94919968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00AL</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Epps Airpark</td>\n",
       "      <td>820</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AL</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>00AL</td>\n",
       "      <td>None</td>\n",
       "      <td>00AL</td>\n",
       "      <td>-86.77030181884766, 34.86479949951172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00AR</td>\n",
       "      <td>closed</td>\n",
       "      <td>Newport Hospital &amp; Clinic Heliport</td>\n",
       "      <td>237</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AR</td>\n",
       "      <td>Newport</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-91.254898, 35.6087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00AS</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Fulton Airport</td>\n",
       "      <td>1100</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-OK</td>\n",
       "      <td>Alex</td>\n",
       "      <td>00AS</td>\n",
       "      <td>None</td>\n",
       "      <td>00AS</td>\n",
       "      <td>-97.8180194, 34.9428028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>00AZ</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Cordes Airport</td>\n",
       "      <td>3810</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AZ</td>\n",
       "      <td>Cordes</td>\n",
       "      <td>00AZ</td>\n",
       "      <td>None</td>\n",
       "      <td>00AZ</td>\n",
       "      <td>-112.16500091552734, 34.305599212646484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>00CA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Goldstone /Gts/ Airport</td>\n",
       "      <td>3038</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-CA</td>\n",
       "      <td>Barstow</td>\n",
       "      <td>00CA</td>\n",
       "      <td>None</td>\n",
       "      <td>00CA</td>\n",
       "      <td>-116.888000488, 35.350498199499995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00CL</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Williams Ag Airport</td>\n",
       "      <td>87</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-CA</td>\n",
       "      <td>Biggs</td>\n",
       "      <td>00CL</td>\n",
       "      <td>None</td>\n",
       "      <td>00CL</td>\n",
       "      <td>-121.763427, 39.427188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00CN</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Kitchen Creek Helibase Heliport</td>\n",
       "      <td>3350</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-CA</td>\n",
       "      <td>Pine Valley</td>\n",
       "      <td>00CN</td>\n",
       "      <td>None</td>\n",
       "      <td>00CN</td>\n",
       "      <td>-116.4597417, 32.7273736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ident           type                                name elevation_ft  \\\n",
       "0   00A       heliport                   Total Rf Heliport           11   \n",
       "1  00AA  small_airport                Aero B Ranch Airport         3435   \n",
       "2  00AK  small_airport                        Lowell Field          450   \n",
       "3  00AL  small_airport                        Epps Airpark          820   \n",
       "4  00AR         closed  Newport Hospital & Clinic Heliport          237   \n",
       "5  00AS  small_airport                      Fulton Airport         1100   \n",
       "6  00AZ  small_airport                      Cordes Airport         3810   \n",
       "7  00CA  small_airport             Goldstone /Gts/ Airport         3038   \n",
       "8  00CL  small_airport                 Williams Ag Airport           87   \n",
       "9  00CN       heliport     Kitchen Creek Helibase Heliport         3350   \n",
       "\n",
       "  continent iso_country iso_region  municipality gps_code iata_code  \\\n",
       "0        NA          US      US-PA      Bensalem      00A      None   \n",
       "1        NA          US      US-KS         Leoti     00AA      None   \n",
       "2        NA          US      US-AK  Anchor Point     00AK      None   \n",
       "3        NA          US      US-AL       Harvest     00AL      None   \n",
       "4        NA          US      US-AR       Newport     None      None   \n",
       "5        NA          US      US-OK          Alex     00AS      None   \n",
       "6        NA          US      US-AZ        Cordes     00AZ      None   \n",
       "7        NA          US      US-CA       Barstow     00CA      None   \n",
       "8        NA          US      US-CA         Biggs     00CL      None   \n",
       "9        NA          US      US-CA   Pine Valley     00CN      None   \n",
       "\n",
       "  local_code                              coordinates  \n",
       "0        00A       -74.93360137939453, 40.07080078125  \n",
       "1       00AA                   -101.473911, 38.704022  \n",
       "2       00AK              -151.695999146, 59.94919968  \n",
       "3       00AL    -86.77030181884766, 34.86479949951172  \n",
       "4       None                      -91.254898, 35.6087  \n",
       "5       00AS                  -97.8180194, 34.9428028  \n",
       "6       00AZ  -112.16500091552734, 34.305599212646484  \n",
       "7       00CA       -116.888000488, 35.350498199499995  \n",
       "8       00CL                   -121.763427, 39.427188  \n",
       "9       00CN                 -116.4597417, 32.7273736  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read and visualize the Airport codes dataset\n",
    "df_airport = spark.read.csv(\"/home/workspace/airport-codes_csv.csv\", header=True)\n",
    "df_airport.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55075\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "55075"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of rows in the dataset\n",
    "print(df_airport.count())\n",
    "\n",
    "# Check for duplicates\n",
    "df_airport.dropDuplicates().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7006</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5676</td>\n",
       "      <td>14045</td>\n",
       "      <td>45886</td>\n",
       "      <td>26389</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ident  type  name  elevation_ft  continent  iso_country  iso_region  \\\n",
       "0      0     0     0          7006          0            0           0   \n",
       "\n",
       "   municipality  gps_code  iata_code  local_code  coordinates  \n",
       "0          5676     14045      45886       26389            0  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for null values in each column of the Airport codes dataset\n",
    "df_airport.select([count(when(isnan(cc) | col(cc).isNull(), cc)).alias(cc) for cc in df_airport.columns]).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|iso_country|\n",
      "+-----------+\n",
      "|         DZ|\n",
      "|         LT|\n",
      "|         MM|\n",
      "|         CI|\n",
      "|         TC|\n",
      "|         AZ|\n",
      "|         FI|\n",
      "|         SC|\n",
      "|         PM|\n",
      "|         UA|\n",
      "|         ZM|\n",
      "|         KI|\n",
      "|         RO|\n",
      "|         SL|\n",
      "|         SB|\n",
      "|         NL|\n",
      "|         LA|\n",
      "|         BS|\n",
      "|         BW|\n",
      "|         MN|\n",
      "+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check how many countries and its airports are included in the dataset\n",
    "df_airport.select('iso_country').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|          type|\n",
      "+--------------+\n",
      "| large_airport|\n",
      "|   balloonport|\n",
      "| seaplane_base|\n",
      "|      heliport|\n",
      "|        closed|\n",
      "|medium_airport|\n",
      "| small_airport|\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_airport.select('type').distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### It looks like that the Dataframe contains details about airports from many countries. In my case I am interested in the airport which are located in the US, which could be the point of entry for the immigrants into the US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00A</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Total Rf Heliport</td>\n",
       "      <td>11</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-PA</td>\n",
       "      <td>Bensalem</td>\n",
       "      <td>00A</td>\n",
       "      <td>None</td>\n",
       "      <td>00A</td>\n",
       "      <td>-74.93360137939453, 40.07080078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00AA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Aero B Ranch Airport</td>\n",
       "      <td>3435</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-KS</td>\n",
       "      <td>Leoti</td>\n",
       "      <td>00AA</td>\n",
       "      <td>None</td>\n",
       "      <td>00AA</td>\n",
       "      <td>-101.473911, 38.704022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00AK</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Lowell Field</td>\n",
       "      <td>450</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Anchor Point</td>\n",
       "      <td>00AK</td>\n",
       "      <td>None</td>\n",
       "      <td>00AK</td>\n",
       "      <td>-151.695999146, 59.94919968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00AL</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Epps Airpark</td>\n",
       "      <td>820</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AL</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>00AL</td>\n",
       "      <td>None</td>\n",
       "      <td>00AL</td>\n",
       "      <td>-86.77030181884766, 34.86479949951172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00AR</td>\n",
       "      <td>closed</td>\n",
       "      <td>Newport Hospital &amp; Clinic Heliport</td>\n",
       "      <td>237</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AR</td>\n",
       "      <td>Newport</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-91.254898, 35.6087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ident           type                                name elevation_ft  \\\n",
       "0   00A       heliport                   Total Rf Heliport           11   \n",
       "1  00AA  small_airport                Aero B Ranch Airport         3435   \n",
       "2  00AK  small_airport                        Lowell Field          450   \n",
       "3  00AL  small_airport                        Epps Airpark          820   \n",
       "4  00AR         closed  Newport Hospital & Clinic Heliport          237   \n",
       "\n",
       "  continent iso_country iso_region  municipality gps_code iata_code  \\\n",
       "0        NA          US      US-PA      Bensalem      00A      None   \n",
       "1        NA          US      US-KS         Leoti     00AA      None   \n",
       "2        NA          US      US-AK  Anchor Point     00AK      None   \n",
       "3        NA          US      US-AL       Harvest     00AL      None   \n",
       "4        NA          US      US-AR       Newport     None      None   \n",
       "\n",
       "  local_code                            coordinates  \n",
       "0        00A     -74.93360137939453, 40.07080078125  \n",
       "1       00AA                 -101.473911, 38.704022  \n",
       "2       00AK            -151.695999146, 59.94919968  \n",
       "3       00AL  -86.77030181884766, 34.86479949951172  \n",
       "4       None                    -91.254898, 35.6087  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter the Airport codes dataframes to get the airports only from the US\n",
    "df_airport_us = df_airport.filter(col('iso_country') == 'US')\n",
    "df_airport_us.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>state</th>\n",
       "      <th>port_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00A</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Total Rf Heliport</td>\n",
       "      <td>11</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-PA</td>\n",
       "      <td>Bensalem</td>\n",
       "      <td>00A</td>\n",
       "      <td>None</td>\n",
       "      <td>00A</td>\n",
       "      <td>-74.93360137939453, 40.07080078125</td>\n",
       "      <td>PA</td>\n",
       "      <td>PENNSYLVANIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00AA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Aero B Ranch Airport</td>\n",
       "      <td>3435</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-KS</td>\n",
       "      <td>Leoti</td>\n",
       "      <td>00AA</td>\n",
       "      <td>None</td>\n",
       "      <td>00AA</td>\n",
       "      <td>-101.473911, 38.704022</td>\n",
       "      <td>KS</td>\n",
       "      <td>KANSAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00AK</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Lowell Field</td>\n",
       "      <td>450</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Anchor Point</td>\n",
       "      <td>00AK</td>\n",
       "      <td>None</td>\n",
       "      <td>00AK</td>\n",
       "      <td>-151.695999146, 59.94919968</td>\n",
       "      <td>AK</td>\n",
       "      <td>ALASKA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00AL</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Epps Airpark</td>\n",
       "      <td>820</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AL</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>00AL</td>\n",
       "      <td>None</td>\n",
       "      <td>00AL</td>\n",
       "      <td>-86.77030181884766, 34.86479949951172</td>\n",
       "      <td>AL</td>\n",
       "      <td>ALABAMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00AR</td>\n",
       "      <td>closed</td>\n",
       "      <td>Newport Hospital &amp; Clinic Heliport</td>\n",
       "      <td>237</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AR</td>\n",
       "      <td>Newport</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-91.254898, 35.6087</td>\n",
       "      <td>AR</td>\n",
       "      <td>ARKANSAS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ident           type                                name elevation_ft  \\\n",
       "0   00A       heliport                   Total Rf Heliport           11   \n",
       "1  00AA  small_airport                Aero B Ranch Airport         3435   \n",
       "2  00AK  small_airport                        Lowell Field          450   \n",
       "3  00AL  small_airport                        Epps Airpark          820   \n",
       "4  00AR         closed  Newport Hospital & Clinic Heliport          237   \n",
       "\n",
       "  continent iso_country iso_region  municipality gps_code iata_code  \\\n",
       "0        NA          US      US-PA      Bensalem      00A      None   \n",
       "1        NA          US      US-KS         Leoti     00AA      None   \n",
       "2        NA          US      US-AK  Anchor Point     00AK      None   \n",
       "3        NA          US      US-AL       Harvest     00AL      None   \n",
       "4        NA          US      US-AR       Newport     None      None   \n",
       "\n",
       "  local_code                            coordinates state    port_state  \n",
       "0        00A     -74.93360137939453, 40.07080078125    PA  PENNSYLVANIA  \n",
       "1       00AA                 -101.473911, 38.704022    KS        KANSAS  \n",
       "2       00AK            -151.695999146, 59.94919968    AK        ALASKA  \n",
       "3       00AL  -86.77030181884766, 34.86479949951172    AL       ALABAMA  \n",
       "4       None                    -91.254898, 35.6087    AR      ARKANSAS  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the string in the column iso_region to get the US States\n",
    "df_airport_us = df_airport_us.withColumn('state', F.split(col('iso_region'), '-').getItem(1))\n",
    "\n",
    "# Get the name of the states from the dictionary valid address and map the values into the new column\n",
    "df_airport_us = df_airport_us.withColumn(\"port_state\", mapping_expr2.getItem(col(\"state\")))\n",
    "df_airport_us.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|       port_state|\n",
      "+-----------------+\n",
      "|       NEW JERSEY|\n",
      "|     PENNSYLVANIA|\n",
      "|         ILLINOIS|\n",
      "|         MARYLAND|\n",
      "|DIST. OF COLUMBIA|\n",
      "|            IDAHO|\n",
      "|         MISSOURI|\n",
      "|          MONTANA|\n",
      "|         MICHIGAN|\n",
      "|          FLORIDA|\n",
      "|           OREGON|\n",
      "|             null|\n",
      "|           ALASKA|\n",
      "|        LOUISIANA|\n",
      "|            MAINE|\n",
      "|         OKLAHOMA|\n",
      "|    NEW HAMPSHIRE|\n",
      "|         VIRGINIA|\n",
      "|       WASHINGTON|\n",
      "|      S. CAROLINA|\n",
      "+-----------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "52\n"
     ]
    }
   ],
   "source": [
    "df_airport_us.select('port_state').distinct().show()\n",
    "print(df_airport_us.select('port_state').distinct().count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>state</th>\n",
       "      <th>port_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US-0303</td>\n",
       "      <td>large_airport</td>\n",
       "      <td>atl</td>\n",
       "      <td>None</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-U-A</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-84.375, 33.137551</td>\n",
       "      <td>U</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US-0319</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Ronnie Cole</td>\n",
       "      <td>900</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-U-A</td>\n",
       "      <td>Greenfield</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-85.72268, 39.831008</td>\n",
       "      <td>U</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US-0384</td>\n",
       "      <td>closed</td>\n",
       "      <td>Beacon Station Air Strip</td>\n",
       "      <td>None</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-U-A</td>\n",
       "      <td>Baker</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-116.20977, 35.13047</td>\n",
       "      <td>U</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US-0610</td>\n",
       "      <td>closed</td>\n",
       "      <td>Erase Me 13</td>\n",
       "      <td>None</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-U-A</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0, 0.4</td>\n",
       "      <td>U</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US-0742</td>\n",
       "      <td>medium_airport</td>\n",
       "      <td>34S Airport</td>\n",
       "      <td>None</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-U-A</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-16.875, 19.145168</td>\n",
       "      <td>U</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ident            type                      name elevation_ft continent  \\\n",
       "0  US-0303   large_airport                       atl         None        NA   \n",
       "1  US-0319   small_airport               Ronnie Cole          900        NA   \n",
       "2  US-0384          closed  Beacon Station Air Strip         None        NA   \n",
       "3  US-0610          closed               Erase Me 13         None        NA   \n",
       "4  US-0742  medium_airport               34S Airport         None        NA   \n",
       "\n",
       "  iso_country iso_region municipality gps_code iata_code local_code  \\\n",
       "0          US     US-U-A         None     None      None       None   \n",
       "1          US     US-U-A   Greenfield     None      None       None   \n",
       "2          US     US-U-A        Baker     None      None       None   \n",
       "3          US     US-U-A         None     None      None       None   \n",
       "4          US     US-U-A         None     None      None       None   \n",
       "\n",
       "            coordinates state port_state  \n",
       "0    -84.375, 33.137551     U       None  \n",
       "1  -85.72268, 39.831008     U       None  \n",
       "2  -116.20977, 35.13047     U       None  \n",
       "3                0, 0.4     U       None  \n",
       "4    -16.875, 19.145168     U       None  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for null values and filter them off\n",
    "print(df_airport_us.filter(col('port_state').isNull()).count())\n",
    "\n",
    "df_airport_us.filter(col('port_state').isNull()).limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_airport_us = df_airport_us.filter(col('port_state').isNotNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|          type|\n",
      "+--------------+\n",
      "| large_airport|\n",
      "|   balloonport|\n",
      "| seaplane_base|\n",
      "|      heliport|\n",
      "|        closed|\n",
      "|medium_airport|\n",
      "| small_airport|\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_airport.select('type').distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### World Temperature Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1743-11-01</td>\n",
       "      <td>6.068</td>\n",
       "      <td>1.7369999999999999</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1743-12-01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1744-01-01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1744-02-01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1744-03-01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt AverageTemperature AverageTemperatureUncertainty   City  \\\n",
       "0  1743-11-01              6.068            1.7369999999999999  Århus   \n",
       "1  1743-12-01               None                          None  Århus   \n",
       "2  1744-01-01               None                          None  Århus   \n",
       "3  1744-02-01               None                          None  Århus   \n",
       "4  1744-03-01               None                          None  Århus   \n",
       "\n",
       "   Country Latitude Longitude  \n",
       "0  Denmark   57.05N    10.33E  \n",
       "1  Denmark   57.05N    10.33E  \n",
       "2  Denmark   57.05N    10.33E  \n",
       "3  Denmark   57.05N    10.33E  \n",
       "4  Denmark   57.05N    10.33E  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the dataset and visualize it\n",
    "df_spark_temp =spark.read.csv('../../data2/GlobalLandTemperaturesByCity.csv', header=True)\n",
    "df_spark_temp.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### I can see some that in column *AverageTemperatureUncertainty* I have got lots of digits after the decimal place. I need to take care of that by rounding it off to 3 digits after the decimal place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1743-11-01</td>\n",
       "      <td>6.068</td>\n",
       "      <td>1.737</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1743-12-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1744-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1744-02-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1744-03-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt  AverageTemperature  AverageTemperatureUncertainty   City  \\\n",
       "0  1743-11-01               6.068                          1.737  Århus   \n",
       "1  1743-12-01                 NaN                            NaN  Århus   \n",
       "2  1744-01-01                 NaN                            NaN  Århus   \n",
       "3  1744-02-01                 NaN                            NaN  Århus   \n",
       "4  1744-03-01                 NaN                            NaN  Århus   \n",
       "\n",
       "   Country Latitude Longitude  \n",
       "0  Denmark   57.05N    10.33E  \n",
       "1  Denmark   57.05N    10.33E  \n",
       "2  Denmark   57.05N    10.33E  \n",
       "3  Denmark   57.05N    10.33E  \n",
       "4  Denmark   57.05N    10.33E  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spark_temp = df_spark_temp.withColumn('AverageTemperature', F.round(col('AverageTemperature'), 3))\\\n",
    "                                .withColumn('AverageTemperatureUncertainty', F.round(col('AverageTemperatureUncertainty'), 3))\n",
    "df_spark_temp.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Now better :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8599212\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8599212"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_spark_temp.count())\n",
    "\n",
    "df_spark_temp.dropDuplicates().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>364130</td>\n",
       "      <td>364130</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dt  AverageTemperature  AverageTemperatureUncertainty  City  Country  \\\n",
       "0   0              364130                         364130     0        0   \n",
       "\n",
       "   Latitude  Longitude  \n",
       "0         0          0  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for null values in each column of the World temperature dataframe\n",
    "df_spark_temp.select([count(when(isnan(cc) | col(cc).isNull(), cc)).alias(cc) for cc in df_spark_temp.columns]).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### It looks like that the names of the city have both Capital letter and small letters. In order to maintain consistency I will make all the letter Capitals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>city</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1743-11-01</td>\n",
       "      <td>6.068</td>\n",
       "      <td>1.737</td>\n",
       "      <td>ÅRHUS</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1743-12-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ÅRHUS</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1744-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ÅRHUS</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1744-02-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ÅRHUS</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1744-03-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ÅRHUS</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt  AverageTemperature  AverageTemperatureUncertainty   city  \\\n",
       "0  1743-11-01               6.068                          1.737  ÅRHUS   \n",
       "1  1743-12-01                 NaN                            NaN  ÅRHUS   \n",
       "2  1744-01-01                 NaN                            NaN  ÅRHUS   \n",
       "3  1744-02-01                 NaN                            NaN  ÅRHUS   \n",
       "4  1744-03-01                 NaN                            NaN  ÅRHUS   \n",
       "\n",
       "   Country Latitude Longitude  \n",
       "0  Denmark   57.05N    10.33E  \n",
       "1  Denmark   57.05N    10.33E  \n",
       "2  Denmark   57.05N    10.33E  \n",
       "3  Denmark   57.05N    10.33E  \n",
       "4  Denmark   57.05N    10.33E  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spark_temp = df_spark_temp.withColumn('city', F.upper(col('City')))\n",
    "df_spark_temp.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### We don't need an historic data from 1700s, 1800s, 1900s as we have US Immigration data only from 2016. Therefore, I am filtering which are in 2000s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>city</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-02-01</td>\n",
       "      <td>3.724</td>\n",
       "      <td>0.241</td>\n",
       "      <td>ÅRHUS</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-03-01</td>\n",
       "      <td>3.976</td>\n",
       "      <td>0.296</td>\n",
       "      <td>ÅRHUS</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-04-01</td>\n",
       "      <td>8.321</td>\n",
       "      <td>0.221</td>\n",
       "      <td>ÅRHUS</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-05-01</td>\n",
       "      <td>13.567</td>\n",
       "      <td>0.253</td>\n",
       "      <td>ÅRHUS</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-06-01</td>\n",
       "      <td>14.702</td>\n",
       "      <td>0.240</td>\n",
       "      <td>ÅRHUS</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt  AverageTemperature  AverageTemperatureUncertainty   city  \\\n",
       "0  2000-02-01               3.724                          0.241  ÅRHUS   \n",
       "1  2000-03-01               3.976                          0.296  ÅRHUS   \n",
       "2  2000-04-01               8.321                          0.221  ÅRHUS   \n",
       "3  2000-05-01              13.567                          0.253  ÅRHUS   \n",
       "4  2000-06-01              14.702                          0.240  ÅRHUS   \n",
       "\n",
       "   Country Latitude Longitude  \n",
       "0  Denmark   57.05N    10.33E  \n",
       "1  Denmark   57.05N    10.33E  \n",
       "2  Denmark   57.05N    10.33E  \n",
       "3  Denmark   57.05N    10.33E  \n",
       "4  Denmark   57.05N    10.33E  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spark_temp = df_spark_temp.filter(col('dt') >= '2000-01-01')\n",
    "df_spark_temp.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Drop all the NaN values\n",
    "df_spark_temp = df_spark_temp.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>city</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dt  AverageTemperature  AverageTemperatureUncertainty  city  Country  \\\n",
       "0   0                   0                              0     0        0   \n",
       "\n",
       "   Latitude  Longitude  \n",
       "0         0          0  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the columns for NaN values once again\n",
    "df_spark_temp.select([count(when(isnan(cc) | col(cc).isNull(), cc)).alias(cc) for cc in df_spark_temp.columns]).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "572570"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spark_temp.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "\n",
    "I have chosen the star schema, since it is easy for quering and also fast during aggregation.\n",
    "\n",
    "The ER Diagram below show the conceptual fact and dimension tables that I want to include in my data model\n",
    "\n",
    "Fact Table -\n",
    " * fact_immigration table\n",
    " \n",
    "Dimension Tables -\n",
    " * dim_immigrant table\n",
    " * dim_port table\n",
    " * dim_date table\n",
    " * dim_usdemograph table\n",
    " * dim_usairport table\n",
    " * dim_ustemperature table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "<img src=\"image/ERD_DEND.jpeg\" width=\"50%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 3.2 Mapping Out Data Pipelines\n",
    "The steps required to channel the data into the data model are as follows -\n",
    " 1. Since the i94 dataset contains more information than necessary, use this dataset to create three dimension tables from it\n",
    "     - dim_immigration table which contains the necessary information lije the age, gender, country of origin, etc of the immigrant\n",
    "     - dim_port table which contains the information about the ports in the US\n",
    "     - dim_date table which contains the timestamp, date and all other datetime related information \n",
    "     \n",
    " 2. US demography dataset contains all the demographic data about the US, use this dataset to create the dimension table -\n",
    "      - dim_usdemograph table\n",
    "\n",
    " 3. The df_airport dataframe contains all the necessary information about the airports in the US, use the dataset and to clean it to create the dimension table -\n",
    "       - dim_usairport table\n",
    "       \n",
    " 4. df_spark_temp contains the information about the World's temperature from the year 2000 till 2013, use this dataframe, filter it to contain only the temperatures from the US and create the dimension table -\n",
    "     - dim_ustemperature table\n",
    "     \n",
    " 5. To create the fact table join the dfImmig dataframe with the df_spark_temp dataframe and select all the necessary columns -\n",
    "     - fact_immigration table\n",
    " \n",
    "#### PS: Write all the fact and dimension tables after creation to parquet format\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "from workspace_utils import active_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def process_immigration_data(input_data, output_path):\n",
    "    \"\"\"\n",
    "    Create the following dimension tables\n",
    "    :param input_data: Input dataframe\n",
    "    :param output_path: Path to which parquet file to be written\n",
    "    :return: Immigrant dimension table, Port dimension table and Date dimension table\n",
    "    \"\"\"\n",
    "    with active_session():\n",
    "        dim_immigrant_table = input_data.select(col('i94bir').alias('age').cast(IntegerType()), \n",
    "                                         col('gender'), col('arrival_date'), \n",
    "                                         col('departure_date'), col('visatype'), col('visa_purpose'), \n",
    "                                         col('origin_country'), col('arrival_mode'), col('duration_of_stay'), \n",
    "                                         col('port').alias('port_of_entry'), col('address'), \n",
    "                                         col('i94port').alias('port'), 'occup', 'i94res')\n",
    "    \n",
    "        # Check if there are any negative duration of stay and filter them out. \n",
    "        # We need the duration of stay which has None value, as we don't know, \n",
    "        # if the immigrant left US to another destination or stayed in the US\n",
    "        if (dim_immigrant_table.filter(col('duration_of_stay') < 0).count()) > 0:\n",
    "            dim_immigrant_table = dim_immigrant_table.filter((col('duration_of_stay') > 0) | (col('duration_of_stay').isNull()))\n",
    "        \n",
    "        # Write the immgrant dimension table as a parquet file partitioned by the port of entry\n",
    "        dim_immigrant_table.write.partitionBy('port_of_entry').parquet(output_path +\n",
    "                                                                       \"output_data/dim_immigrant_table/\", 'overwrite')\n",
    "    \n",
    "        # Create Port Dimension Table\n",
    "        dim_port_table = input_data.select('i94port', col('port').alias('port_city'), 'us_state').dropDuplicates()\n",
    "        # Write the port dimension table as a parquet file partitioned by the name of the port cities\n",
    "        dim_port_table.write.partitionBy('port_city').parquet(output_path + \"output_data/dim_port_table/\", 'overwrite')\n",
    "    \n",
    "        # Create Date Dimension Table\n",
    "        dim_date_table = input_data.select(\n",
    "                    'arrival_date',\n",
    "                    'departure_date',\n",
    "                    dayofmonth(\"arrival_date\").alias('arrival_day'),\n",
    "                    weekofyear(\"arrival_date\").alias('arrival_week'),\n",
    "                    month(\"arrival_date\").alias('arrival_month'),\n",
    "                    year(\"arrival_date\").alias('arrival_year'),\n",
    "                    date_format(\"arrival_date\", \"E\").alias(\"arrival_weekday\"),\n",
    "                    dayofmonth(\"departure_date\").alias('departure_day'),\n",
    "                    weekofyear(\"departure_date\").alias('departure_week'),\n",
    "                    month(\"departure_date\").alias('departure_month'),\n",
    "                    year(\"departure_date\").alias('departure_year'),\n",
    "                    date_format(\"departure_date\", \"E\").alias(\"departure_weekday\")\n",
    "                )\n",
    "        # Write the date dimension table as a parquet file\n",
    "        dim_date_table.write.parquet(output_path + \"output_data/dim_date_table/\", 'overwrite')\n",
    "    \n",
    "        return dim_immigrant_table, dim_port_table, dim_date_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def process_demograph_data(input_data, output_path):\n",
    "    \"\"\"\n",
    "    Create the US Demograph dimension table\n",
    "    :param input_data: Input dataframe\n",
    "    :param output_path: Path to which parquet file to be written\n",
    "    :return: US Demograph dimension table\n",
    "    \"\"\"\n",
    "    with active_session():\n",
    "        # Create US Demograph Dimension Table\n",
    "        dim_usdemograph_table = input_data.select(F.upper(col('City')).alias('city'), \n",
    "                                              F.upper(col('State')).alias('state'), \n",
    "                                              col('Male Population').alias('male_poulation'), \n",
    "                                              col('Female Population').alias('female_population'), \n",
    "                                              col('Total Population').alias('total_population'), \n",
    "                                              col('Median Age').alias('median_age').cast(IntegerType()), \n",
    "                                              col('Foreign-born').alias('foreign_born'), \n",
    "                                              col('Number of Veterans').alias('no_of_veterans'), \n",
    "                                              col('Race').alias('ethnicity'), \n",
    "                                              col('Count').alias('ethinicity_count'))\n",
    "        # Write the US demograph dimension table as a parquet file\n",
    "        dim_usdemograph_table.write.partitionBy('state', 'city').parquet(output_path +\n",
    "                                                                         \"output_data/dim_usdemograph_table/\", 'overwrite')\n",
    "    \n",
    "        return dim_usdemograph_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def process_aiport_data(input_data, output_path):\n",
    "    \"\"\"\n",
    "    Create the US Airport dimension table\n",
    "    :param input_data: Input dataframe\n",
    "    :param output_path: Path to which parquet file to be written\n",
    "    :return: US Airport dimension table \n",
    "    \"\"\"\n",
    "    with active_session():\n",
    "        # Create US Airport Dimension Table\n",
    "        dim_usairport_table = input_data.select(col('ident'),\n",
    "                              col('type'),\n",
    "                              col('name'),\n",
    "                              col('elevation_ft'),\n",
    "                              col('iata_code'),\n",
    "                              col('local_code'),\n",
    "                              col('coordinates'),\n",
    "                              col('iso_region'),\n",
    "                              col('port_state'))\n",
    "    \n",
    "        # Add a column 'port_type' which contains a string 'airport'. This could be handy during joins\n",
    "        dim_usairport_table = dim_usairport_table.withColumn('port_type', F.lit('airport'))\n",
    "        # Write the US airport dimension table as a parquet file partitioned by the state in which the port is located\n",
    "        dim_usairport_table.write.partitionBy('port_state').parquet(output_path +\n",
    "                                                                    \"output_data/dim_usairport_table/\", 'overwrite')\n",
    "    \n",
    "        return dim_usairport_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def process_temperature_data(input_data, output_path):\n",
    "    \"\"\"\n",
    "    Create the US Temperature dimension table\n",
    "    :param input_data: Input dataframe\n",
    "    :param output_path: Path to which parquet file to be written\n",
    "    :return: US Temperature dimension table \n",
    "    \"\"\"\n",
    "    with active_session():\n",
    "        # Since I am interested only in the US, I would filter the dataframe and get the rows where *Country = United States*\n",
    "        dim_ustemperature_table = input_data.filter(input_data.Country.contains('United States'))\n",
    "        # Rename the column city to us_city to give a clear idea\n",
    "        dim_ustemperature_table = dim_ustemperature_table.withColumnRenamed('city', 'us_city')\n",
    "        # Drop all the duplicates formed because of the join\n",
    "        dim_ustemperature_table = dim_ustemperature_table.dropDuplicates()\n",
    "        # Write the US temperature dimension table as a parquet file partitioned by the us city \n",
    "        #print(\"Writing the file now to AWS S3\")\n",
    "        \n",
    "        start = time.time()\n",
    "        dim_ustemperature_table.write.partitionBy('us_city').parquet(output_path +\n",
    "                                                                     \"output_data/dim_ustemperature_table/\", \n",
    "                                                                     'overwrite')\n",
    "        \n",
    "        end = time.time()\n",
    "        print(str((end-start)/60)+ ' minutes')\n",
    "    \n",
    "        return dim_ustemperature_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def create_fact_table(df1, df2, output_path):\n",
    "    \"\"\"\n",
    "    Create the US Immigration fact table\n",
    "    :param df1: First dataframe\n",
    "    :param df2: Second dataframe\n",
    "    :param output_path: Path to which parquet file to be written\n",
    "    :return: Immigration fact table \n",
    "    \"\"\"\n",
    "    with active_session():\n",
    "        req_col = ['city', 'Country', 'Latitude', 'Longitude']\n",
    "        df_temp = df2.filter((col('dt') >= '2009-01-01') & df_spark_temp.Country.contains('United States')).groupBy(req_col).agg(F.avg('AverageTemperature').alias('avg_temp'))\n",
    "        #df_temp.count()\n",
    "        \n",
    "        fact_immigration_table = df1.join(df_temp, (df1.port == df_temp.city))\\\n",
    "                .filter(col('port').isNotNull())\\\n",
    "                .withColumn('immigration_id', F.row_number().over(Window.orderBy(F.monotonically_increasing_id())))\\\n",
    "                .select(col('port'), col('i94port'), col('arrival_date'), col('port_type'), \n",
    "                        col('us_state'), col('avg_temp').alias('avg_temperature')).dropDuplicates()\n",
    "        \n",
    "        print(fact_immigration_table.limit(5).toPandas())\n",
    "        \n",
    "        start = time.time()\n",
    "        print(start)\n",
    "        # Write the US immigration fact table as a parquet file partitioned by port \n",
    "        fact_immigration_table.write.partitionBy('port').parquet(output_path +\n",
    "                                                                 \"output_data/fact_immigration_table/\", 'overwrite')\n",
    "        \n",
    "        end = time.time()\n",
    "        print(str((end-start)/60)+ ' minutes')\n",
    "    \n",
    "        return fact_immigration_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "output_path = \"s3a://udacity-dataengg-capstone/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "dim_immigrant_table, dim_port_table, dim_date_table = process_immigration_data(dfImmig, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "dim_usdemograph_table = process_demograph_data(df_city_demograph, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>male_poulation</th>\n",
       "      <th>female_population</th>\n",
       "      <th>total_population</th>\n",
       "      <th>median_age</th>\n",
       "      <th>foreign_born</th>\n",
       "      <th>no_of_veterans</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>ethinicity_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SILVER SPRING</td>\n",
       "      <td>MARYLAND</td>\n",
       "      <td>40601</td>\n",
       "      <td>41862</td>\n",
       "      <td>82463</td>\n",
       "      <td>33</td>\n",
       "      <td>30908</td>\n",
       "      <td>1562</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>QUINCY</td>\n",
       "      <td>MASSACHUSETTS</td>\n",
       "      <td>44129</td>\n",
       "      <td>49500</td>\n",
       "      <td>93629</td>\n",
       "      <td>41</td>\n",
       "      <td>32935</td>\n",
       "      <td>4147</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOOVER</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>38040</td>\n",
       "      <td>46799</td>\n",
       "      <td>84839</td>\n",
       "      <td>38</td>\n",
       "      <td>8229</td>\n",
       "      <td>4819</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RANCHO CUCAMONGA</td>\n",
       "      <td>CALIFORNIA</td>\n",
       "      <td>88127</td>\n",
       "      <td>87105</td>\n",
       "      <td>175232</td>\n",
       "      <td>34</td>\n",
       "      <td>33878</td>\n",
       "      <td>5821</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>24437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NEWARK</td>\n",
       "      <td>NEW JERSEY</td>\n",
       "      <td>138040</td>\n",
       "      <td>143873</td>\n",
       "      <td>281913</td>\n",
       "      <td>34</td>\n",
       "      <td>86253</td>\n",
       "      <td>5829</td>\n",
       "      <td>White</td>\n",
       "      <td>76402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               city          state male_poulation female_population  \\\n",
       "0     SILVER SPRING       MARYLAND          40601             41862   \n",
       "1            QUINCY  MASSACHUSETTS          44129             49500   \n",
       "2            HOOVER        ALABAMA          38040             46799   \n",
       "3  RANCHO CUCAMONGA     CALIFORNIA          88127             87105   \n",
       "4            NEWARK     NEW JERSEY         138040            143873   \n",
       "\n",
       "  total_population  median_age foreign_born no_of_veterans  \\\n",
       "0            82463          33        30908           1562   \n",
       "1            93629          41        32935           4147   \n",
       "2            84839          38         8229           4819   \n",
       "3           175232          34        33878           5821   \n",
       "4           281913          34        86253           5829   \n",
       "\n",
       "                   ethnicity ethinicity_count  \n",
       "0         Hispanic or Latino            25924  \n",
       "1                      White            58723  \n",
       "2                      Asian             4759  \n",
       "3  Black or African-American            24437  \n",
       "4                      White            76402  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_usdemograph_table.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "dim_usairport_table = process_aiport_data(df_airport_us, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>port_state</th>\n",
       "      <th>port_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00A</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Total Rf Heliport</td>\n",
       "      <td>11</td>\n",
       "      <td>None</td>\n",
       "      <td>00A</td>\n",
       "      <td>-74.93360137939453, 40.07080078125</td>\n",
       "      <td>US-PA</td>\n",
       "      <td>PENNSYLVANIA</td>\n",
       "      <td>airport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00AA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Aero B Ranch Airport</td>\n",
       "      <td>3435</td>\n",
       "      <td>None</td>\n",
       "      <td>00AA</td>\n",
       "      <td>-101.473911, 38.704022</td>\n",
       "      <td>US-KS</td>\n",
       "      <td>KANSAS</td>\n",
       "      <td>airport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00AK</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Lowell Field</td>\n",
       "      <td>450</td>\n",
       "      <td>None</td>\n",
       "      <td>00AK</td>\n",
       "      <td>-151.695999146, 59.94919968</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>ALASKA</td>\n",
       "      <td>airport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00AL</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Epps Airpark</td>\n",
       "      <td>820</td>\n",
       "      <td>None</td>\n",
       "      <td>00AL</td>\n",
       "      <td>-86.77030181884766, 34.86479949951172</td>\n",
       "      <td>US-AL</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>airport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00AR</td>\n",
       "      <td>closed</td>\n",
       "      <td>Newport Hospital &amp; Clinic Heliport</td>\n",
       "      <td>237</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-91.254898, 35.6087</td>\n",
       "      <td>US-AR</td>\n",
       "      <td>ARKANSAS</td>\n",
       "      <td>airport</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ident           type                                name elevation_ft  \\\n",
       "0   00A       heliport                   Total Rf Heliport           11   \n",
       "1  00AA  small_airport                Aero B Ranch Airport         3435   \n",
       "2  00AK  small_airport                        Lowell Field          450   \n",
       "3  00AL  small_airport                        Epps Airpark          820   \n",
       "4  00AR         closed  Newport Hospital & Clinic Heliport          237   \n",
       "\n",
       "  iata_code local_code                            coordinates iso_region  \\\n",
       "0      None        00A     -74.93360137939453, 40.07080078125      US-PA   \n",
       "1      None       00AA                 -101.473911, 38.704022      US-KS   \n",
       "2      None       00AK            -151.695999146, 59.94919968      US-AK   \n",
       "3      None       00AL  -86.77030181884766, 34.86479949951172      US-AL   \n",
       "4      None       None                    -91.254898, 35.6087      US-AR   \n",
       "\n",
       "     port_state port_type  \n",
       "0  PENNSYLVANIA   airport  \n",
       "1        KANSAS   airport  \n",
       "2        ALASKA   airport  \n",
       "3       ALABAMA   airport  \n",
       "4      ARKANSAS   airport  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_usairport_table.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.068682173887889 minutes\n"
     ]
    }
   ],
   "source": [
    "dim_ustemperature_table = process_temperature_data(df_spark_temp, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      port i94port         arrival_date port_type us_state  avg_temperature\n",
      "0  ORLANDO     ORL  2016-07-24T00:00:00   airport  FLORIDA        23.268339\n",
      "1  ORLANDO     ORL  2016-07-25T00:00:00   airport  FLORIDA        23.268339\n",
      "2  ORLANDO     ORL  2016-07-26T00:00:00   airport  FLORIDA        23.268339\n",
      "3  ORLANDO     ORL  2016-07-27T00:00:00   airport  FLORIDA        23.268339\n",
      "4  ORLANDO     ORL  2016-07-29T00:00:00   airport  FLORIDA        23.268339\n",
      "1597093760.249533\n",
      "10.520065184434255 minutes\n"
     ]
    }
   ],
   "source": [
    "fact_immigration_table = create_fact_table(dfImmig, df_spark_temp, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "filepath = \"s3a://udacity-dataengg-capstone/output_data/\"\n",
    "dim_immigrant_table = spark.read.parquet(filepath + \"dim_immigrant_table/\")\n",
    "dim_port_table = spark.read.parquet(filepath + \"dim_port_table/\")\n",
    "dim_date_table = spark.read.parquet(filepath + \"dim_date_table/\")\n",
    "dim_usdemograph_table = spark.read.parquet(filepath + \"dim_usdemograph_table/\")\n",
    "dim_usairport_table = spark.read.parquet(filepath + \"dim_usairport_table/\")\n",
    "dim_ustemperature_table = spark.read.parquet(filepath + \"dim_ustemperature_table/\")\n",
    "fact_immigration_table = spark.read.parquet(filepath + \"fact_immigration_table/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>arrival_date</th>\n",
       "      <th>departure_date</th>\n",
       "      <th>visatype</th>\n",
       "      <th>visa_purpose</th>\n",
       "      <th>origin_country</th>\n",
       "      <th>arrival_mode</th>\n",
       "      <th>duration_of_stay</th>\n",
       "      <th>address</th>\n",
       "      <th>port</th>\n",
       "      <th>occup</th>\n",
       "      <th>i94res</th>\n",
       "      <th>port_of_entry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>None</td>\n",
       "      <td>2016-10-26T00:00:00</td>\n",
       "      <td>2016-11-01T00:00:00</td>\n",
       "      <td>B2</td>\n",
       "      <td>pleasure</td>\n",
       "      <td>BRAZIL</td>\n",
       "      <td>air</td>\n",
       "      <td>6</td>\n",
       "      <td>NEBRASKA</td>\n",
       "      <td>NYC</td>\n",
       "      <td>None</td>\n",
       "      <td>689.0</td>\n",
       "      <td>NEW YORK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>F</td>\n",
       "      <td>2016-10-29T00:00:00</td>\n",
       "      <td>2016-11-05T00:00:00</td>\n",
       "      <td>WT</td>\n",
       "      <td>pleasure</td>\n",
       "      <td>ITALY</td>\n",
       "      <td>air</td>\n",
       "      <td>7</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>NYC</td>\n",
       "      <td>None</td>\n",
       "      <td>117.0</td>\n",
       "      <td>NEW YORK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48</td>\n",
       "      <td>F</td>\n",
       "      <td>2016-10-26T00:00:00</td>\n",
       "      <td>2016-11-07T00:00:00</td>\n",
       "      <td>B2</td>\n",
       "      <td>pleasure</td>\n",
       "      <td>CHINA, PRC</td>\n",
       "      <td>air</td>\n",
       "      <td>12</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>NYC</td>\n",
       "      <td>None</td>\n",
       "      <td>245.0</td>\n",
       "      <td>NEW YORK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>M</td>\n",
       "      <td>2016-10-29T00:00:00</td>\n",
       "      <td>2016-11-07T00:00:00</td>\n",
       "      <td>WT</td>\n",
       "      <td>pleasure</td>\n",
       "      <td>IRELAND</td>\n",
       "      <td>air</td>\n",
       "      <td>9</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>NYC</td>\n",
       "      <td>None</td>\n",
       "      <td>116.0</td>\n",
       "      <td>NEW YORK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34</td>\n",
       "      <td>M</td>\n",
       "      <td>2016-10-26T00:00:00</td>\n",
       "      <td>2016-11-04T00:00:00</td>\n",
       "      <td>B1</td>\n",
       "      <td>business</td>\n",
       "      <td>CHINA, PRC</td>\n",
       "      <td>air</td>\n",
       "      <td>9</td>\n",
       "      <td>NEW JERSEY</td>\n",
       "      <td>NYC</td>\n",
       "      <td>None</td>\n",
       "      <td>245.0</td>\n",
       "      <td>NEW YORK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age gender         arrival_date       departure_date visatype visa_purpose  \\\n",
       "0   30   None  2016-10-26T00:00:00  2016-11-01T00:00:00       B2     pleasure   \n",
       "1   53      F  2016-10-29T00:00:00  2016-11-05T00:00:00       WT     pleasure   \n",
       "2   48      F  2016-10-26T00:00:00  2016-11-07T00:00:00       B2     pleasure   \n",
       "3   16      M  2016-10-29T00:00:00  2016-11-07T00:00:00       WT     pleasure   \n",
       "4   34      M  2016-10-26T00:00:00  2016-11-04T00:00:00       B1     business   \n",
       "\n",
       "  origin_country arrival_mode  duration_of_stay     address port occup  \\\n",
       "0         BRAZIL          air                 6    NEBRASKA  NYC  None   \n",
       "1          ITALY          air                 7    NEW YORK  NYC  None   \n",
       "2     CHINA, PRC          air                12    NEW YORK  NYC  None   \n",
       "3        IRELAND          air                 9    NEW YORK  NYC  None   \n",
       "4     CHINA, PRC          air                 9  NEW JERSEY  NYC  None   \n",
       "\n",
       "   i94res port_of_entry  \n",
       "0   689.0      NEW YORK  \n",
       "1   117.0      NEW YORK  \n",
       "2   245.0      NEW YORK  \n",
       "3   116.0      NEW YORK  \n",
       "4   245.0      NEW YORK  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_immigrant_table.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i94port</th>\n",
       "      <th>us_state</th>\n",
       "      <th>port_city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NYC</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>NEW YORK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NYC</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>NEW YORK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NYC</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>NEW YORK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NYC</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>NEW YORK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NYC</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>NEW YORK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  i94port  us_state port_city\n",
       "0     NYC  NEW YORK  NEW YORK\n",
       "1     NYC  NEW YORK  NEW YORK\n",
       "2     NYC  NEW YORK  NEW YORK\n",
       "3     NYC  NEW YORK  NEW YORK\n",
       "4     NYC  NEW YORK  NEW YORK"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_port_table.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male_poulation</th>\n",
       "      <th>female_population</th>\n",
       "      <th>total_population</th>\n",
       "      <th>median_age</th>\n",
       "      <th>foreign_born</th>\n",
       "      <th>no_of_veterans</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>ethinicity_count</th>\n",
       "      <th>state</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4081698</td>\n",
       "      <td>4468707</td>\n",
       "      <td>8550405</td>\n",
       "      <td>36</td>\n",
       "      <td>3212500</td>\n",
       "      <td>156961</td>\n",
       "      <td>White</td>\n",
       "      <td>3835726</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>NEW YORK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4081698</td>\n",
       "      <td>4468707</td>\n",
       "      <td>8550405</td>\n",
       "      <td>36</td>\n",
       "      <td>3212500</td>\n",
       "      <td>156961</td>\n",
       "      <td>Asian</td>\n",
       "      <td>1304564</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>NEW YORK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4081698</td>\n",
       "      <td>4468707</td>\n",
       "      <td>8550405</td>\n",
       "      <td>36</td>\n",
       "      <td>3212500</td>\n",
       "      <td>156961</td>\n",
       "      <td>American Indian and Alaska Native</td>\n",
       "      <td>90923</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>NEW YORK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4081698</td>\n",
       "      <td>4468707</td>\n",
       "      <td>8550405</td>\n",
       "      <td>36</td>\n",
       "      <td>3212500</td>\n",
       "      <td>156961</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>2485125</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>NEW YORK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4081698</td>\n",
       "      <td>4468707</td>\n",
       "      <td>8550405</td>\n",
       "      <td>36</td>\n",
       "      <td>3212500</td>\n",
       "      <td>156961</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>2192248</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>NEW YORK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  male_poulation female_population total_population  median_age foreign_born  \\\n",
       "0        4081698           4468707          8550405          36      3212500   \n",
       "1        4081698           4468707          8550405          36      3212500   \n",
       "2        4081698           4468707          8550405          36      3212500   \n",
       "3        4081698           4468707          8550405          36      3212500   \n",
       "4        4081698           4468707          8550405          36      3212500   \n",
       "\n",
       "  no_of_veterans                          ethnicity ethinicity_count  \\\n",
       "0         156961                              White          3835726   \n",
       "1         156961                              Asian          1304564   \n",
       "2         156961  American Indian and Alaska Native            90923   \n",
       "3         156961                 Hispanic or Latino          2485125   \n",
       "4         156961          Black or African-American          2192248   \n",
       "\n",
       "      state      city  \n",
       "0  NEW YORK  NEW YORK  \n",
       "1  NEW YORK  NEW YORK  \n",
       "2  NEW YORK  NEW YORK  \n",
       "3  NEW YORK  NEW YORK  \n",
       "4  NEW YORK  NEW YORK  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_usdemograph_table.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>port_type</th>\n",
       "      <th>port_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00TA</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Sw Region Faa Heliport</td>\n",
       "      <td>598</td>\n",
       "      <td>None</td>\n",
       "      <td>00TA</td>\n",
       "      <td>-97.30580139160156, 32.826900482177734</td>\n",
       "      <td>US-TX</td>\n",
       "      <td>airport</td>\n",
       "      <td>TEXAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00TE</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Tcjc-Northeast Campus Heliport</td>\n",
       "      <td>600</td>\n",
       "      <td>None</td>\n",
       "      <td>00TE</td>\n",
       "      <td>-97.18949890136719, 32.847599029541016</td>\n",
       "      <td>US-TX</td>\n",
       "      <td>airport</td>\n",
       "      <td>TEXAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00TS</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Alpine Range Airport</td>\n",
       "      <td>670</td>\n",
       "      <td>None</td>\n",
       "      <td>00TS</td>\n",
       "      <td>-97.24199676513672, 32.607601165771484</td>\n",
       "      <td>US-TX</td>\n",
       "      <td>airport</td>\n",
       "      <td>TEXAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00TX</td>\n",
       "      <td>closed</td>\n",
       "      <td>San Jacinto Methodist Hospital Heliport</td>\n",
       "      <td>19</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-94.980201, 29.7377</td>\n",
       "      <td>US-TX</td>\n",
       "      <td>airport</td>\n",
       "      <td>TEXAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00XS</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>L P Askew Farms Airport</td>\n",
       "      <td>3110</td>\n",
       "      <td>None</td>\n",
       "      <td>00XS</td>\n",
       "      <td>-101.93399810791016, 33.03340148925781</td>\n",
       "      <td>US-TX</td>\n",
       "      <td>airport</td>\n",
       "      <td>TEXAS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ident           type                                     name elevation_ft  \\\n",
       "0  00TA       heliport                   Sw Region Faa Heliport          598   \n",
       "1  00TE       heliport           Tcjc-Northeast Campus Heliport          600   \n",
       "2  00TS  small_airport                     Alpine Range Airport          670   \n",
       "3  00TX         closed  San Jacinto Methodist Hospital Heliport           19   \n",
       "4  00XS  small_airport                  L P Askew Farms Airport         3110   \n",
       "\n",
       "  iata_code local_code                             coordinates iso_region  \\\n",
       "0      None       00TA  -97.30580139160156, 32.826900482177734      US-TX   \n",
       "1      None       00TE  -97.18949890136719, 32.847599029541016      US-TX   \n",
       "2      None       00TS  -97.24199676513672, 32.607601165771484      US-TX   \n",
       "3      None       None                     -94.980201, 29.7377      US-TX   \n",
       "4      None       00XS  -101.93399810791016, 33.03340148925781      US-TX   \n",
       "\n",
       "  port_type port_state  \n",
       "0   airport      TEXAS  \n",
       "1   airport      TEXAS  \n",
       "2   airport      TEXAS  \n",
       "3   airport      TEXAS  \n",
       "4   airport      TEXAS  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_usairport_table.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>us_city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2002-04-01</td>\n",
       "      <td>18.366</td>\n",
       "      <td>0.366</td>\n",
       "      <td>United States</td>\n",
       "      <td>36.17N</td>\n",
       "      <td>115.36W</td>\n",
       "      <td>SPRING VALLEY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2002-10-01</td>\n",
       "      <td>17.170</td>\n",
       "      <td>0.322</td>\n",
       "      <td>United States</td>\n",
       "      <td>36.17N</td>\n",
       "      <td>115.36W</td>\n",
       "      <td>SPRING VALLEY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2002-12-01</td>\n",
       "      <td>6.258</td>\n",
       "      <td>0.235</td>\n",
       "      <td>United States</td>\n",
       "      <td>36.17N</td>\n",
       "      <td>115.36W</td>\n",
       "      <td>SPRING VALLEY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2005-03-01</td>\n",
       "      <td>12.268</td>\n",
       "      <td>0.189</td>\n",
       "      <td>United States</td>\n",
       "      <td>36.17N</td>\n",
       "      <td>115.36W</td>\n",
       "      <td>SPRING VALLEY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006-10-01</td>\n",
       "      <td>16.934</td>\n",
       "      <td>0.245</td>\n",
       "      <td>United States</td>\n",
       "      <td>36.17N</td>\n",
       "      <td>115.36W</td>\n",
       "      <td>SPRING VALLEY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt  AverageTemperature  AverageTemperatureUncertainty  \\\n",
       "0  2002-04-01              18.366                          0.366   \n",
       "1  2002-10-01              17.170                          0.322   \n",
       "2  2002-12-01               6.258                          0.235   \n",
       "3  2005-03-01              12.268                          0.189   \n",
       "4  2006-10-01              16.934                          0.245   \n",
       "\n",
       "         Country Latitude Longitude        us_city  \n",
       "0  United States   36.17N   115.36W  SPRING VALLEY  \n",
       "1  United States   36.17N   115.36W  SPRING VALLEY  \n",
       "2  United States   36.17N   115.36W  SPRING VALLEY  \n",
       "3  United States   36.17N   115.36W  SPRING VALLEY  \n",
       "4  United States   36.17N   115.36W  SPRING VALLEY  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_ustemperature_table.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "   age gender         arrival_date       departure_date visatype visa_purpose  \\\n",
      "0   30   None  2016-10-26T00:00:00  2016-11-01T00:00:00       B2     pleasure   \n",
      "1   53      F  2016-10-29T00:00:00  2016-11-05T00:00:00       WT     pleasure   \n",
      "2   48      F  2016-10-26T00:00:00  2016-11-07T00:00:00       B2     pleasure   \n",
      "3   16      M  2016-10-29T00:00:00  2016-11-07T00:00:00       WT     pleasure   \n",
      "4   34      M  2016-10-26T00:00:00  2016-11-04T00:00:00       B1     business   \n",
      "\n",
      "  origin_country arrival_mode  duration_of_stay     address port occup  \\\n",
      "0         BRAZIL          air                 6    NEBRASKA  NYC  None   \n",
      "1          ITALY          air                 7    NEW YORK  NYC  None   \n",
      "2     CHINA, PRC          air                12    NEW YORK  NYC  None   \n",
      "3        IRELAND          air                 9    NEW YORK  NYC  None   \n",
      "4     CHINA, PRC          air                 9  NEW JERSEY  NYC  None   \n",
      "\n",
      "   i94res port_of_entry  \n",
      "0   689.0      NEW YORK  \n",
      "1   117.0      NEW YORK  \n",
      "2   245.0      NEW YORK  \n",
      "3   116.0      NEW YORK  \n",
      "4   245.0      NEW YORK  \n",
      "****************************************************************************************************\n",
      "  i94port        us_state         port_city\n",
      "0     CHA  VIRGIN ISLANDS  CHARLOTTE AMALIE\n",
      "1     STT  VIRGIN ISLANDS         ST THOMAS\n",
      "2     CHR  VIRGIN ISLANDS     CHRISTIANSTED\n",
      "3     PSM   NEW HAMPSHIRE        PORTSMOUTH\n",
      "4     PNH   NEW HAMPSHIRE         PITTSBURG\n",
      "****************************************************************************************************\n",
      "          arrival_date       departure_date  arrival_day  arrival_week  \\\n",
      "0  2016-10-29T00:00:00  2016-11-05T00:00:00           29            43   \n",
      "1  2016-10-29T00:00:00  2016-11-04T00:00:00           29            43   \n",
      "2  2016-10-29T00:00:00  2016-11-05T00:00:00           29            43   \n",
      "3  2016-10-29T00:00:00  2016-11-01T00:00:00           29            43   \n",
      "4  2016-10-29T00:00:00  2016-11-01T00:00:00           29            43   \n",
      "\n",
      "   arrival_month  arrival_year arrival_weekday  departure_day  departure_week  \\\n",
      "0             10          2016             Sat              5              44   \n",
      "1             10          2016             Sat              4              44   \n",
      "2             10          2016             Sat              5              44   \n",
      "3             10          2016             Sat              1              44   \n",
      "4             10          2016             Sat              1              44   \n",
      "\n",
      "   departure_month  departure_year departure_weekday  \n",
      "0               11            2016               Sat  \n",
      "1               11            2016               Fri  \n",
      "2               11            2016               Sat  \n",
      "3               11            2016               Tue  \n",
      "4               11            2016               Tue  \n",
      "****************************************************************************************************\n",
      "  male_poulation female_population total_population  median_age foreign_born  \\\n",
      "0        4081698           4468707          8550405          36      3212500   \n",
      "1        4081698           4468707          8550405          36      3212500   \n",
      "2        4081698           4468707          8550405          36      3212500   \n",
      "3        4081698           4468707          8550405          36      3212500   \n",
      "4        4081698           4468707          8550405          36      3212500   \n",
      "\n",
      "  no_of_veterans                          ethnicity ethinicity_count  \\\n",
      "0         156961                              White          3835726   \n",
      "1         156961                              Asian          1304564   \n",
      "2         156961  American Indian and Alaska Native            90923   \n",
      "3         156961                 Hispanic or Latino          2485125   \n",
      "4         156961          Black or African-American          2192248   \n",
      "\n",
      "      state      city  \n",
      "0  NEW YORK  NEW YORK  \n",
      "1  NEW YORK  NEW YORK  \n",
      "2  NEW YORK  NEW YORK  \n",
      "3  NEW YORK  NEW YORK  \n",
      "4  NEW YORK  NEW YORK  \n",
      "****************************************************************************************************\n",
      "  ident           type                                     name elevation_ft  \\\n",
      "0  00TA       heliport                   Sw Region Faa Heliport          598   \n",
      "1  00TE       heliport           Tcjc-Northeast Campus Heliport          600   \n",
      "2  00TS  small_airport                     Alpine Range Airport          670   \n",
      "3  00TX         closed  San Jacinto Methodist Hospital Heliport           19   \n",
      "4  00XS  small_airport                  L P Askew Farms Airport         3110   \n",
      "\n",
      "  iata_code local_code                             coordinates iso_region  \\\n",
      "0      None       00TA  -97.30580139160156, 32.826900482177734      US-TX   \n",
      "1      None       00TE  -97.18949890136719, 32.847599029541016      US-TX   \n",
      "2      None       00TS  -97.24199676513672, 32.607601165771484      US-TX   \n",
      "3      None       None                     -94.980201, 29.7377      US-TX   \n",
      "4      None       00XS  -101.93399810791016, 33.03340148925781      US-TX   \n",
      "\n",
      "  port_type port_state  \n",
      "0   airport      TEXAS  \n",
      "1   airport      TEXAS  \n",
      "2   airport      TEXAS  \n",
      "3   airport      TEXAS  \n",
      "4   airport      TEXAS  \n",
      "****************************************************************************************************\n",
      "           dt  AverageTemperature  AverageTemperatureUncertainty  \\\n",
      "0  2002-04-01              18.366                          0.366   \n",
      "1  2002-10-01              17.170                          0.322   \n",
      "2  2002-12-01               6.258                          0.235   \n",
      "3  2005-03-01              12.268                          0.189   \n",
      "4  2006-10-01              16.934                          0.245   \n",
      "\n",
      "         Country Latitude Longitude        us_city  \n",
      "0  United States   36.17N   115.36W  SPRING VALLEY  \n",
      "1  United States   36.17N   115.36W  SPRING VALLEY  \n",
      "2  United States   36.17N   115.36W  SPRING VALLEY  \n",
      "3  United States   36.17N   115.36W  SPRING VALLEY  \n",
      "4  United States   36.17N   115.36W  SPRING VALLEY  \n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "print('*'*100)\n",
    "print(dim_immigrant_table.limit(5).toPandas())\n",
    "print('*'*100)\n",
    "print(dim_port_table.limit(5).toPandas())\n",
    "print('*'*100)\n",
    "print(dim_date_table.limit(5).toPandas())\n",
    "print('*'*100)\n",
    "print(dim_usdemograph_table.limit(5).toPandas())\n",
    "print('*'*100)\n",
    "print(dim_usairport_table.limit(5).toPandas())\n",
    "print('*'*100)\n",
    "print(dim_ustemperature_table.limit(5).toPandas())\n",
    "print('*'*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def check_rows(input_data):\n",
    "    \"\"\"\n",
    "    Perform data count check\n",
    "    :param input_data: dataframe to check\n",
    "    :return: True or False\n",
    "    \"\"\"\n",
    "    check = input_data.count() > 0\n",
    "    return check\n",
    "\n",
    "def integrity_check(fact, dimen, column_fact, column_dim):\n",
    "    \"\"\"\n",
    "    Perform integrity to check the integrity between the fact and dimension tables\n",
    "    :param fact: immigration fact table\n",
    "    :param dimen: dimension table\n",
    "    :column_fact: column of the fact table for join operation\n",
    "    :column_dim: column of the dimension table for join operation\n",
    "    :return: True or False (if False the reason behind it)\n",
    "    \"\"\"\n",
    "    check = fact.select(column_fact).distinct() \\\n",
    "            .join(dimen, fact[column_fact] == dimen[column_dim], \"left_anti\") \\\n",
    "            .count() == 0\n",
    "    if not check:\n",
    "        dftmp_ = fact.select(column_fact).distinct() \\\n",
    "            .join(dimen, fact[column_fact] == dimen[column_dim], \"left_anti\")\n",
    "        \n",
    "        #if not 'f' in df.columns:\n",
    "            \n",
    "        if dftmp_.filter(col(column_fact).isNull()).collect():\n",
    "            print(\"The {} column has null values\".format(column_fact))\n",
    "        \n",
    "        elif column_dim in dftmp_.columns:\n",
    "            if dftmp_.filter(col(column_dim).isNull()).collect():\n",
    "                print(\"The {} column has null values\".format(column_dim))\n",
    "        else:\n",
    "            print(\"The integrity test fail due to the following:\")\n",
    "            print('__' * 50)\n",
    "            print(dftmp_.limit(5).toPandas())\n",
    "        return check\n",
    "    else:\n",
    "        return check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "integrity_check(fact_immigration_table, dim_immigrant_table, \"port\", \"port_of_entry\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "integrity_check(fact_immigration_table, dim_date_table, \"arrival_date\", \"arrival_date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The integrity test fail due to the following:\n",
      "____________________________________________________________________________________________________\n",
      "         port\n",
      "0  LOUISVILLE\n",
      "1     NOGALES\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "integrity_check(fact_immigration_table, dim_usdemograph_table, \"port\", \"city\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The us_state column has null values\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "integrity_check(fact_immigration_table, dim_usairport_table, \"us_state\", \"port_state\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "integrity_check(fact_immigration_table, dim_port_table, \"i94port\", \"i94port\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "integrity_check(fact_immigration_table, dim_ustemperature_table, \"port\", \"us_city\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_rows(dim_port_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_rows(dim_usairport_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_rows(dim_usdemograph_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_rows(dim_date_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_rows(dim_immigrant_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_rows(dim_ustemperature_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_rows(fact_immigration_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    "\n",
    "##### Fact Table\n",
    "\n",
    " * fact_immigration table contains the \n",
    "     * immigration_id : Unique ID for each immigration\n",
    "     * i94port : Three letter code for the port\n",
    "     * port : The city in which port is located\n",
    "     * arrival_date : Immigrant's arrival date to the US\n",
    "     * port_type : The type of port (airport, seaport, landport)\n",
    "     * us_state : The state of the US\n",
    "     * avg_temperature : The average temperature \n",
    "     \n",
    "##### Dimension Tables\n",
    "\n",
    " * dim_immigrant table\n",
    "     * port_of_entry : The port of entry for the immigrant\n",
    "     * age : The age of the immigrant\n",
    "     * gender : The gender of the immigrant\n",
    "     * arrival_date : The date on which the immigrant entered the US\n",
    "     * departure_date : The date on which the immigrant departed from the US\n",
    "     * visatype : The type of Visa issued to the immigrant\n",
    "     * visa_purpose : The purpose due to which the Visa was issued to the immigrant\n",
    "     * origin_country : Origin country of the immigrant\n",
    "     * arrival_mode : Arrival mode (air, sea, land)\n",
    "     * duration_of_stay : The duration of the stay in the US\n",
    "     * address : The address of the immigrant in the US\n",
    "     * port : Three letter code for the port\n",
    "     * occup : occupation of the immigrant\n",
    "     * i94res : Three letter code for the origin country\n",
    "     \n",
    " * dim_port table\n",
    "     * i94port : Three letter code for the port\n",
    "     * us_state : The state of the US\n",
    "     * port_city :  The city in which the port is located\n",
    "     \n",
    " * dim_date table\n",
    "     * arrival_date : Timestamp for arrival \n",
    "     * departure_date : Timestamp for departure \n",
    "     * arrival_day : The date of arrival\n",
    "     * arrival_week : The week of arrival\n",
    "     * arrival_month : The month of arrival\n",
    "     * arrival_year : The year of arrival\n",
    "     * arrival_weekday : The weekday of arrival\n",
    "     * departure_day : The day of departure\n",
    "     * departure_week : The weekof departure\n",
    "     * departure_month : The month of departure\n",
    "     * departure_year : The year of departure\n",
    "     * departure_weekday : The weekday of departure\n",
    "     \n",
    " * dim_usdemograph table\n",
    "     * city : City in US\n",
    "     * state : State in the US\n",
    "     * male_population : Male population in a city\n",
    "     * female_population : Female population in a city\n",
    "     * total_population : Total population in a city\n",
    "     * median_age : The median age of the population\n",
    "     * foreign_born : Number of foreign born in the population\n",
    "     * no_of_veterans : Number of veterans in the population\n",
    "     * ethnicity : Ethnicity\n",
    "     * ethnicity_count : Count of the respective ethnicity\n",
    "     \n",
    " * dim_usairport table\n",
    "     * port_state : State in the US where port is located\n",
    "     * ident : Unique ID of the port\n",
    "     * type : Type of the port\n",
    "     * name : Name of the port\n",
    "     * elevation_ft : The elevation of the port in feet\n",
    "     * iata_code : IATA code for the port\n",
    "     * local_code : Local code for the port\n",
    "     * coordinates : Coordinates of the port\n",
    "     * iso_region : Region code of the port\n",
    "     * port_type : The type of the port\n",
    "     \n",
    " * dim_ustemperature\n",
    "     * us_city : The city in the US\n",
    "     * dt : Date\n",
    "     * AverageTemperature : The Average temperature\n",
    "     * AverageTemperatureUncertainty : The uncertainty of the temperature\n",
    "     * Country : The country (in this case only United States)\n",
    "     * Latitude : Latitude\n",
    "     * Longitude : Longitude\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    " - I have choose Python Library Pandas to explore the dataset as it more user-friendly, can efficiently handle bigger datasets and has an extensive set of features that helps us to explore and visualize the dataset easily. Secondly I have used the Python API for Spark i.e., Pyspark as it is more efficient when handling Big Data and because of distributed computing property and the power of spark could be improved by horizontally scaling up of the hardware. I have use the cloud storage service S3 from the AWS as it is easy to use, cheap and safe.\n",
    " \n",
    "* Propose how often the data should be updated and why.\n",
    " - I think after exploring the US immigration data seeing the trend as the dataset was provided on a monthly basis, it would be best to continue the monthly updation of the dataset for efficient processing of the dataset. In case if any use case arises which could require daily or weekly updation, we have the tools which could be adjusted according for efficient processing of the dataset.\n",
    " \n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    "     - In this case I would leverage the power of the AWS EMR cluster for processing and S3 for storage and let the autoscaling do the job in case we need more of less spark workers.\n",
    "     \n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    "     - In this case a cron job for scheduling the job or building the datapipeline with Airflow and scheduling its run by specifying the suitable start date \n",
    "     \n",
    " * The database needed to be accessed by 100+ people.\n",
    "     - Either Amazon S3 or Redshift come into the picture which would satify our need and the choice between S3 and Redshift could be made on the use case\n",
    "     - [Correction]The more people accessing the database the more CPU resources you need to get a fast experience. By using a distributed database you can improve your replications and partitioning to get faster query results for each user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
